<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[春天的一些照片]]></title>
    <url>%2F2018%2F04%2F22%2F%E6%98%A5%E5%A4%A9%E7%9A%84%E4%B8%80%E4%BA%9B%E7%85%A7%E7%89%87%2F</url>
    <content type="text"><![CDATA[照片非出自本人，双休日这么好的日子，宅着，看看nba, 看看番。 2018年3月，同事去某个植物园，可能是上海植物园，陶堰情操，拍拍花草，感觉比以前拍的好看点。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>photo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[静态博客太好用！！！]]></title>
    <url>%2F2018%2F04%2F22%2F%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E5%A4%AA%E5%A5%BD%E7%94%A8%EF%BC%81%EF%BC%81%EF%BC%81%2F</url>
    <content type="text"><![CDATA[用hexo搭的这个博客， 太好搭了，就用了node.js和git, 不需要vps, 省钱。之前flask搭的那个博客，要先看完书，然后找了一个别人写好的框架，一步一步网上谷歌，废了九牛二虎之力才弄好， 弄完后眼睛那个酸。这个flask博客还是蛮好看的，羡慕别人怎么就可以写的出这么好的框架。 hexo博客优点：样式简洁美观上传文章超级方便 hexo n, hexo g, hexo s, hexo d 不过发现图片总是404错误，于是在vps上搭了个图床，第一次发现宝塔这个工具，真是强大方便。。。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>吐槽</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C08_Object References, Mutability, and Recycling_01]]></title>
    <url>%2F2018%2F04%2F22%2FC08-Object-References-Mutability-and-Recycling-01%2F</url>
    <content type="text"><![CDATA[The distinction between objects and their names. A name is not the object; a name is a separate thing. Variables Are Not BoxesIt’s better to think of Python variables as labels attached to objects Variables a and b hold references to the same list, not copies of the list12345&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; a.append(4)&gt;&gt;&gt; b[1, 2, 3, 4] With reference variables, it makes much more sense to say that the variable is assigned to an object,and not the other way around. After all, the object is created before the assignment. The righthand side of an assignment happens first(Variables are assigned to objects only after the objects are created) 1234567891011121314&gt;&gt;&gt; class Gizmo:... def __init__(self):... print('Gizmo id: %d' % id(self))...&gt;&gt;&gt; x = Gizmo()Gizmo id: 4301489152# a second Gizmo was actually instantiated before the multiplication was attempted.&gt;&gt;&gt; y = Gizmo() * 10 Gizmo id: 4301489432Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: unsupported operand type(s) for *: 'Gizmo' and 'int' Identity, Equality, and Aliasescharles and lewis refer to the same object123456789&gt;&gt;&gt; charles = &#123;'name': 'Charles L. Dodgson', 'born': 1832&#125;&gt;&gt;&gt; lewis = charles # lewis is an alias for charles.&gt;&gt;&gt; lewis is charlesTrue&gt;&gt;&gt; id(charles), id(lewis) (4300473992, 4300473992)&gt;&gt;&gt; lewis['balance'] = 950&gt;&gt;&gt; charles&#123;'name': 'Charles L. Dodgson', 'balance': 950, 'born': 1832&#125; alex and charles compare equal, but alex is not charles #alex refers to an object that is a replica of the object assigned to charles.12345&gt;&gt;&gt; alex = &#123;'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950&#125;&gt;&gt;&gt; alex == charlesTrue&gt;&gt;&gt; alex is not charlesTrue In The Python Language Reference, “3.1. Objects, values and types” states: Every object has an identity, a type and a value. An object’s identity never changes onceit has been created; you may think of it as the object’s address in memory. The is operatorcompares the identity of two objects; the id() function returns an integer representingits identity. In CPython, id() returns the memory address of the object, but it may be something else in anotherPython interpreter. The key point is that the ID is guaranteed to be a unique numeric label, and it willnever change during the life of the object. Choosing Between == and isThe == operator compares the values of objects (the data they hold), while is compares theiridentities. checking whether a variable is bound to Nonex is None The is operator is faster than ==, because it cannot be overloaded, so Python does not have tofind and invoke special methods to evaluate it, and computing is as simple as comparing two integer IDs.In contrast, a == b is syntactic sugar for a.__eq__(b). The __eq__ method inherited fromobject compares object IDs, so it produces the same result as is. The Relative Immutability of TuplesTuples, like most Python collections—lists, dicts, sets, etc.—hold references toobjects.If the referenced items are mutable, they may change even if the tuple itself does not. Inother words, the immutability of tuples really refers to the physical contents of the tuple datastructure (i.e., the references it holds), and does not extend to the referenced objects.1234567891011121314&gt;&gt;&gt; t1 = (1, 2, [30, 40])&gt;&gt;&gt; t2 = (1, 2, [30, 40])&gt;&gt;&gt; t1 == t2True&gt;&gt;&gt; id(t1[-1])4302515784&gt;&gt;&gt; t1[-1].append(99)&gt;&gt;&gt; t1(1, 2, [30, 40, 99])&gt;&gt;&gt; id(t1[-1]) #The identity of t1[-1] has not changed, only its value.4302515784&gt;&gt;&gt; t1 == t2False Copies Are Shallow by Default12345678&gt;&gt;&gt; l1 = [3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 = list(l1) #list(l1) creates a copy of l1.&gt;&gt;&gt; l2[3, [55, 44], (7, 8, 9)]&gt;&gt;&gt; l2 == l1True&gt;&gt;&gt; l2 is l1 #The copies are equal. But refer to two different objectsFalse For lists and other mutable sequences, the shortcut l2 = l1[:] also makes a copy. Using the constructor or [:] produces a shallow copy (i.e., the outermost container is duplicated,but the copy is filled with references to the same items held by the original container). This savesmemory and causes no problems if all the items are immutable. But if there are mutable items, this maylead to unpleasant surprises. Making a shallow copy of a list containing another list 123456789101112131415161718192021l1 = [3, [66, 55, 44], (7, 8, 9)]l2 = list(l1) #l1.append(100) #l1[1].remove(55) #print('l1:', l1)print('l2:', l2)l2[1] += [33, 22] #l2[2] += (10, 11) #print('l1:', l1)print('l2:', l2)#ouput:l1: [3, [66, 44], (7, 8, 9), 100]l2: [3, [66, 44], (7, 8, 9)]#For a mutable object like the list referred by l2[1], the operator += changes the list in place. This change #is visible at l1[1], which is an alias for l2[1].l1: [3, [66, 44, 33, 22], (7, 8, 9), 100]# += on a tuple creates a new tuple and rebinds the variable l2[2] here. This is the same as doing l2[2] = # l2[2] + (10, 11). Now the tuples in the last position of l1 and l2 are no longer the same object. l2: [3, [66, 44, 33, 22], (7, 8, 9, 10, 11)] Deep and Shallow Copies of Arbitrary ObjectsThe copy module provides the deepcopy and copy functions that return deep and shallowcopies of arbitrary objects.1234567891011121314class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers=[] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) Effects of using copy versus deepcopy1234567891011121314151617&gt;&gt;&gt; import copy&gt;&gt;&gt; bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])&gt;&gt;&gt; bus2 = copy.copy(bus1)&gt;&gt;&gt; bus3 = copy.deepcopy(bus1)#Using copy and deepcopy, we create three distinct Bus instances.&gt;&gt;&gt; id(bus1), id(bus2), id(bus3)(4301498296, 4301499416, 4301499752)&gt;&gt;&gt; bus1.drop('Bill')&gt;&gt;&gt; bus2.passengers['Alice', 'Claire', 'David']&gt;&gt;&gt; id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)(4302658568, 4302658568, 4302657800)&gt;&gt;&gt; bus3.passengers['Alice', 'Bill', 'Claire', 'David'] Cyclic references: b refers to a, and then is appended to a; deepcopy still manages to copy a 123456789&gt;&gt;&gt; a=[10,20]&gt;&gt;&gt; b=[a,30]&gt;&gt;&gt; a.append(b)&gt;&gt;&gt; a[10, 20, [[...], 30]]&gt;&gt;&gt; from copy import deepcopy&gt;&gt;&gt; c=deepcopy(a)&gt;&gt;&gt; c[10, 20, [[...], 30]]]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C07_Stacked Decorators_Parameterized Decorators]]></title>
    <url>%2F2018%2F04%2F22%2FC07-Stacked-Decorators-Parameterized-Decorators%2F</url>
    <content type="text"><![CDATA[Stacked DecoratorsWhen two decorators @d1 and @d2 are applied to a function f in that order, the result isthe same as f = d1(d2(f)). Parameterized DecoratorsWhen parsing a decorator in source code, Python takes the decorated function and passes it as the firstargument to the decorator function. So how do you make a decorator accept other arguments? Theanswer is: make a decorator factory that takes those arguments and returns a decorator, which is thenapplied to the function to be decorated._registration_param.py_12345678910111213141516171819202122registry=set()def register(active=True): def decorate(func): print('running register (active=%s) -&gt; decorate(%s)')%(active, func) if active: registry.add(func) else: registry.discard(func) return func return decorate@register(active=False)def f1(): print('running f1()')@register(active=True)def f2(): print('running f2()')def f3(): print('running f3()') _Using the registration_param module_123456789101112131415&gt;&gt;&gt; from registration_param import *running register(active=False)-&gt;decorate(&lt;function f1 at 0x10073c1e0&gt;)running register(active=True)-&gt;decorate(&lt;function f2 at 0x10073c268&gt;)&gt;&gt;&gt; registry #&#123;&lt;function f2 at 0x10073c268&gt;&#125;&gt;&gt;&gt; register()(f3) #running register(active=True)-&gt;decorate(&lt;function f3 at 0x10073c158&gt;)&lt;function f3 at 0x10073c158&gt;&gt;&gt;&gt; registry #&#123;&lt;function f3 at 0x10073c158&gt;, &lt;function f2 at 0x10073c268&gt;&#125;&gt;&gt;&gt; register(active=False)(f2) #running register(active=False)-&gt;decorate(&lt;function f2 at 0x10073c268&gt;)&lt;function f2 at 0x10073c268&gt;&gt;&gt;&gt; registry #&#123;&lt;function f3 at 0x10073c158&gt;&#125; _clockdeco_param.py_12345678910111213141516171819202122232425262728293031323334import timeDEFAULT_FMT='[&#123;elasped: 0.8f&#125;s &#123;name&#125;(&#123;args&#125;) -&gt; &#123;result&#125;]'def clock(fmt=DEFAULT_FMT): def decorate(func): def clocked(*_args): t0=time.time() _result=func(*_args) elapsed=time.time()- t0 name=func.__name__ #_args holds the actual arguments of clocked args=', '.join(repr(arg) for arg in _args) result=repr(_result) #Using **locals() here allows any local variable of #clocked to be referenced in the fmt. print(fmt.format(**locals())) return _result return clocked return decorateif __name__=='__main__': @clock() def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123)# output:$ python3 clockdeco_param.py[0.12412500s] snooze(0.123) -&gt; None[0.12411904s] snooze(0.123) -&gt; None[0.12410498s] snooze(0.123) -&gt; None _clockdeco_param_demo1.py_ 12345678910111213import timefrom clockdeco_param import clock@clock('&#123;name&#125;: &#123;elapsed&#125;s')def snooze(seconds): time.sleep(seconds)for i in range(3): snooze(.123)# output:$ python3 clockdeco_param_demo1.pysnooze: 0.12414693832397461ssnooze: 0.1241159439086914ssnooze: 0.12412118911743164s _clockdeco_param_demo2.py_12345678910111213import timefrom clockdeco_param import clock@clock('&#123;name&#125;(&#123;args&#125;) dt=&#123;elapsed:0.3f&#125;s')def snooze(seconds): time.sleep(seconds)for i in range(3): snooze(.123)# output:$ python3 clockdeco_param_demo2.pysnooze(0.123) dt=0.124ssnooze(0.123) dt=0.124ssnooze(0.123) dt=0.124s]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C07_Implementing a Simple Decorator]]></title>
    <url>%2F2018%2F04%2F22%2FC07-Implementing-a-Simple-Decorator%2F</url>
    <content type="text"><![CDATA[clockdeco.py: 12345678910import timedef clock(func): def clocked(*args): t0=time.perf_counter() result=func(*args) elapsed=time.perf_counter()- t0 name=func.__name__ arg_str=', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -&gt; %r'%(elapsed, name, arg_str, result)) return clocked _clockdeco_demo.py:_ 123456789101112131415161718192021import timefrom clockdeco import clock@clockdef snooze(seconds): time.sleep(seconds)@clockdef factorial(n): return 1 if n ==1 else n * factorial(n-1)if __name__ == '__main__': print('*'*40, 'Calling snooze(.123)') snooze(.123) print('*'*40, 'Calling factorial(6)') print('6!= ', factorial(6))&gt;&gt;&gt; import clockdeco_demo&gt;&gt;&gt; clockdeco_demo.factorial.__name__'clocked' So factorial now actually holds a reference to the clocked function. The typical behavior of a decorator: it replaces the decorated function with a new function that accepts the same arguments and (usually) returns whatever the decorated function was supposed to return, while also doing some extra processing. functools.wrapsThe clock decorator has a few shortcomings: it does not support keyword arguments, and it masksthe __name__ and __doc__ of the decorated function. clockdeco2.py1234567891011121314151617181920import timeimport functoolsdef clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0=time.time() result=func(*args, **kwargs) elapsed=time.time() - t0 name=func.__name__ arg_lst=[] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs=['%s = %s' %(k,w) for k,w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str=', '.join(arg_lst) print('[%0.8fs] %s(%s) -&gt; %r'%(elapsed, name, arg_str, result)) return result return clocked functools.lru_cacheA very practical decorator is functools.lru_cache. It implements memoization: an optimizationtechnique that works by saving the results of previous invocations of an expensive function, avoidingrepeat computations on previously used arguments. The letters LRU stand for Least Recently Used,meaning that the growth of the cache is limited by discarding the entries that have not been read for awhile. _fibo_demo.py_1234567891011121314151617181920212223242526272829303132333435from clockdeco import clock@clockdef fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)if __name__=='__main__': print(fibonacci(6))# $ python3 fibo_demo.py# [0.00000095s] fibonacci(0) -&gt; 0# [0.00000095s] fibonacci(1) -&gt; 1# [0.00007892s] fibonacci(2) -&gt; 1# [0.00000095s] fibonacci(1) -&gt; 1# [0.00000095s] fibonacci(0) -&gt; 0# [0.00000095s] fibonacci(1) -&gt; 1# [0.00003815s] fibonacci(2) -&gt; 1# [0.00007391s] fibonacci(3) -&gt; 2# [0.00018883s] fibonacci(4) -&gt; 3# [0.00000000s] fibonacci(1) -&gt; 1# [0.00000095s] fibonacci(0) -&gt; 0# [0.00000119s] fibonacci(1) -&gt; 1# [0.00004911s] fibonacci(2) -&gt; 1# [0.00009704s] fibonacci(3) -&gt; 2# [0.00000000s] fibonacci(0) -&gt; 0# [0.00000000s] fibonacci(1) -&gt; 1# [0.00002694s] fibonacci(2) -&gt; 1# [0.00000095s] fibonacci(1) -&gt; 1# [0.00000095s] fibonacci(0) -&gt; 0# [0.00000095s] fibonacci(1) -&gt; 1# [0.00005102s] fibonacci(2) -&gt; 1# [0.00008917s] fibonacci(3) -&gt; 2# [0.00015593s] fibonacci(4) -&gt; 3# [0.00029993s] fibonacci(5) -&gt; 5# [0.00052810s] fibonacci(6) -&gt; 8# 8 _fibo_demo_lru.py_12345678910111213141516import functools from clockdeco import clock@functools.lru_cache()@clockdef fibnacci(n): if n &lt; 2: return n return fibnacci(n-2)+ fibnacci(n-1)$ python3 fibo_demo_lru.py# [0.00000119s] fibonacci(0) -&gt; 0# [0.00000119s] fibonacci(1) -&gt; 1# [0.00010800s] fibonacci(2) -&gt; 1# [0.00000787s] fibonacci(3) -&gt; 2# [0.00016093s] fibonacci(4) -&gt; 3# [0.00001216s] fibonacci(5) -&gt; 5# [0.00025296s] fibonacci(6) -&gt; 8 lru_cache can be tuned by passing two optional arguments. Its full signature is: functools.lru_cache(maxsize=128, typed=False) The maxsize argument determines how many call results are stored. After the cache is full, older results are discarded to make room. For optimal performance, maxsize should be a power of 2. The typed argument, if set to True, stores results of different argument types separately, i.e., distinguishing between float and integer arguments that are normally considered equal, like 1 and 1.0. By the way, because lru_cache uses a dict to store the results, and the keys are made from the positional and keyword arguments used in the calls, all the arguments taken by the decorated function must be hashable. functools.singledispatchIf you decorate a plain function with @singledispatch, it becomes a generic function: a group offunctions to perform the same operation in different ways, depending on the type of the first argument. 123456789101112131415161718192021222324252627from functools import singledispatchfrom collections import abcimport numbersimport html@singledispatchdef htmlize(obj): content=html.escape(repr(obj)) return '&lt;pre&gt;&#123;&#125;&lt;/pre&gt;'.format(content)@htmlize.register(str)def _(text): content=html.escape(text).replace('\n','&lt;br&gt;\n') return '&lt;p&gt;&#123;0&#125;&lt;/p&gt;'.format(content)#numbers.Integral is a virtual superclass of int.@htmlize.register(numbers.Integral)def _(n): return '&lt;pre&gt;&#123;0&#125; (0x&#123;0:x&#125;)&lt;/pre&gt;'.format(n) #stack several register decorators to support different types #with the same function@htmlize.register(tuple)@htmlize.register(abc.MutableSequence)def _(seq): inner='&lt;/li&gt;\n&lt;li&gt;'.join(htmlize(item) for item in seq) return '&lt;ul&gt;\n&lt;li&gt;'+inner+'&lt;/li&gt;\n&lt;/ul&gt;']]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C07_Function Decorators and Closures_02]]></title>
    <url>%2F2018%2F04%2F22%2FC07-Function-Decorators-and-Closures-02%2F</url>
    <content type="text"><![CDATA[ClosuresA closure is a function with an extended scope that encompasses nonglobal variables referencedin the body of the function but not defined there. It does not matter whether the function is anonymousor not; what matters is that it can access nonglobal variables that are defined outside of its body.A class to calculate a running average12345678910class Averager(): def __init__(self): self.series=[] def __call__(self, new_value): self.series.append(new_value) total=sum(self.series) return total / len(self.series) A higher-order function to calculate a running average12345678910def make_averager(): series=[] def averager(new_value): series.append(new_value) total=sum(series) return total / len(series) return averager When invoked, make_averager returns an averager function object. Each time anaverager is called, it appends the passed argument to the series, and computes the currentaverage, as shown: 1234567&gt;&gt;&gt; avg = make_averager()&gt;&gt;&gt; avg(10)10.0&gt;&gt;&gt; avg(11)10.5&gt;&gt;&gt; avg(12)11.0 _inspecting the function created by make_average_ 1234&gt;&gt;&gt; avg.__code__.co_varnames('new_value', 'total')&gt;&gt;&gt; avg.__code__.co_freevars('series',) The binding for series is kept in the __closure__ attribute of the returned function avg. Each item inavg.__closure__corresponds to a name in avg.__closure__**.co_free vars. These items are cells, and they have an attribute called cell_contents** where the actual value can be found. A closure is a function that retains the bindings of the free variables that exist when the function isdefined, so that they can be used later when the function is invoked and the defining scope is no longeravailable. nonlocal Declaration123456789101112131415161718def make_averager(): count=0 total=0 def averager(new_value): count += 1 total += new_value return total / count return averager&gt;&gt;&gt; avg= make_averager()&gt;&gt;&gt; avg(10)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 6, in averagerUnboundLocalError: local variable 'count' referenced before assignment The problem is that the statement count += 1 actually means the same as count = count + 1,when count is a number or any immutable type. So we are actually assigning to count in the bodyof averager, and that makes it a local variable. The same problem affects the total variable. We did not have this problem in series because we never assigned to the series name; we onlycalled series.append and invoked sum and len on it. So we took advantage of the fact that lists are mutable. But with immutable types like numbers, strings, tuples, etc., all you can do is read, but never update. Ifyou try to rebind them, as in count = count + 1, then you are implicitly creating a local variablecount. It is no longer a free variable, and therefore it is not saved in the closure. To work around this, the nonlocal declaration was introduced in Python 3. It lets you flag a variable asa free variable even when it is assigned a new value within the function. If a new value is assigned to anonlocal variable, the binding stored in the closure is changed. Calculate a running average without keeping all history (fixed with the use of nonlocal) 123456789def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C07_Function Decorators and Closures01]]></title>
    <url>%2F2018%2F04%2F22%2FC07-Function-Decorators-and-Closures01%2F</url>
    <content type="text"><![CDATA[decoratorA decorator is a callable that takes another function as argument (the decorated function). Thedecorator may perform some processing with the decorated function, and returns it or replaces it withanother function or callable object. 1234567891011&gt;&gt;&gt; def deco(func):... def inner():... print('running inner')... return inner&gt;&gt;&gt; @deco... def target():... print('running target()')&gt;&gt;&gt; target()running inner&gt;&gt;&gt; target&lt;function deco.&lt;locals&gt;.inner at 0x05CDF348&gt; The first crucial fact about decorators is that they have the power to replace the decoratedfunction with a different one. The second crucial fact is that they are executed immediately when a moduleis loaded. This is explained next. When Python Executes Decorators123456789101112131415161718192021222324252627282930313233# _registration.py_registry=[]def register(func): print('running register(%s)'%func) registry.append(func) return func@registerdef f1(): print('running f1()')@registerdef f2():print('running f2()')def f3():print('running f3()')def main(): print('running main()') print('registry -&gt;', registry) f1() f2() f3()if __name__ == '__main__': main()#If registration.py is imported&gt;&gt;&gt; importregistrationrunning register(&lt;function f1 at 0x10063b1e0&gt;)running register(&lt;function f2 at 0x10063b268&gt;)&gt;&gt;&gt; registration.registry[&lt;function f1 at 0x10063b1e0&gt;, &lt;function f2 at 0x10063b268&gt;] decorators are executed as soon as the module is imported, but the decorated functions only runwhen they are explicitly invoked. This highlights the difference between what Pythonistas call importtime and runtime. Considering how decorators are commonly employed in real code, above example is unusual in two ways: The decorator function is defined in the same module as the decorated functions. A real decorator is usually defined in one module and applied to functions in other modules. The register decorator returns the same function passed as argument. In practice, most decorators define an inner function and return it. Decorator-Enhanced Strategy Pattern1234567891011121314151617181920212223242526272829303132promos=[]def promotion(promo_func): promos.append(promo_func) return promo_func@promotiondef fidelity(order): """5% discount for customers with 1000 or more fidelity points""" return order.total() *0.05 if order.customer.fidelity &gt;=1000 else 0@promotiondef bulk_item(order): """10% discount for each LineItem with 20 or more units""" discount=0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * 0.1 return discount@promotiondef large_order(order): """7% discount for orders with 10 or more distinct items""" distinct_items=&#123;item.product for item in order.cart&#125; if len(distinct_items) &gt;= 10: return order.total() * 0.07 return 0def best_promo(order): """Select best discount available""" return max(promo(order) for promo in promos) Most decorators do change the decorated function. They usually do it by defining an inner function andreturning it to replace the decorated function. Code that uses inner functions almost always depends onclosures to operate correctly. Variable Scope Rules12345678910111213&gt;&gt;&gt; b=6&gt;&gt;&gt; def f2(a):... print(a)... print(b)... b=9... &gt;&gt;&gt; f2(3)3Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in f2UnboundLocalError: local variable 'b' referenced before assignment When Python compiles the body of the function, it decides that b is a local variable because it is assigned within the function. Python does not require you to declare variables, but assumes that a variable assigned in thebody of a function is local. This is much better than the behavior of JavaScript, which doesnot require variable declarations either, but if you do forget to declare that a variable is local (withvar), you may clobber a global variable without knowing. If we want the interpreter to treat b as a global variable in spite of the assignment within the function,we use the global declaration： 1234567891011121314&gt;&gt;&gt; def f3(a):... global b... print(a)... print(b)... b=9... &gt;&gt;&gt; f3(3)36&gt;&gt;&gt; b9&gt;&gt;&gt; f3(3)39]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C06_design pattern- Command]]></title>
    <url>%2F2018%2F04%2F22%2FC06-design-pattern-Command%2F</url>
    <content type="text"><![CDATA[Command is another design pattern that can be simplified by the use of functions passed as arguments. MacroCommand12345678class MacroCommand: def __init__(self, commands): self.commands=list(commands) def __call__(self): for command in self.commands: command() More advanced uses of the Command pattern—to support undo, for example—may require morethan a simple callback function. Even then, Python provides a couple of alternatives that deserveconsideration: A callable instance like MacroCommand can keep whatever state is necessary, and provide extra methods in addition to __call__. A closure can be used to hold the internal state of a function between calls.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C06_Strategy Design and Function-Oriented Strategy]]></title>
    <url>%2F2018%2F04%2F22%2FC06-Strategy-Design-and-Function-Oriented-Strategy%2F</url>
    <content type="text"><![CDATA[Strategy Designpromotion.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576from abc import ABC, abstractmethodfrom collections import namedtupleCustomer=namedtuple('Customer', 'name fidelity')class LineItem: def __init__(self,product,quantity,price): self.product=product self.quantity=quantity self.price=price def total(self): return self.price * self.quantityclass Order: def __init__(self, customer,cart, promotion=None): self.customer=customer self.cart=list(cart) self.promotion=promotion def total(self): if not hasattr(self,'__total'): self.__total=sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount=0 else: discount=self.promotion.discount(self) return self.total()- discount def __repr__(self): fmt='&lt;Order total: &#123;:.2f&#125; due: &#123;:.2f&#125;&gt;' return fmt.format(self.total, self.due())class Promotion(ABC): @abstractmethod def discount(self,order): ''' return discount as a positive dollar amount '''class FidelityPromo(Promotion): ''' 5% discount for customers with 1000 or more fidelity points ''' def discount(self, order): return order.total() *0.05 if order.customer.fidelity &gt;=1000 else 0class BulkItemPromo(Promotion): ''' 10% discount for each LineItem with 20 or more units ''' def discount(self, order): discount=0 for item in order.cart: if item.quantity &gt;= 20: discount+= item.total() * 0.1 return discountclass LargeOrderPromo(Promotion): ''' "7% discount for orders with 10 or more distinct items ''' def discount(self, order): distinct_items=&#123;item.products for item in order.cart&#125; if len(distinct_items) &gt; 10: return order.total() * 0.07 return 0 Sample usage of Order class with different promotions applied12345678910111213141516171819&gt;&gt;&gt; joe = Customer('John Doe', 0) &gt;&gt;&gt; ann = Customer('Ann Smith', 1100) &gt;&gt;&gt; cart = [LineItem('banana', 4, .5), ... LineItem('apple', 10, 1.5), ... LineItem('watermellon', 5, 5.0)] &gt;&gt;&gt; Order(joe, cart, FidelityPromo()) &lt;Order total: 42.00 due: 42.00&gt; &gt;&gt;&gt; Order(ann, cart, FidelityPromo()) &lt;Order total: 42.00 due: 39.90&gt; &gt;&gt;&gt; banana_cart = [LineItem('banana', 30, .5), ... LineItem('apple', 10, 1.5)] &gt;&gt;&gt; Order(joe, banana_cart, BulkItemPromo()) &lt;Order total: 30.00 due: 28.50&gt; &gt;&gt;&gt; long_order = [LineItem(str(item_code), 1, 1.0) ... for item_code in range(10)] &gt;&gt;&gt; Order(joe, long_order, LargeOrderPromo()) &lt;Order total: 10.00 due: 9.30&gt; &gt;&gt;&gt; Order(joe, cart, LargeOrderPromo()) &lt;Order total: 42.00 due: 42.00&gt; Function-Oriented Strategy123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from collections import namedtupleCustomer = namedtuple('Customer', 'name fidelity')class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantityclass Order: # the Context def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) # &lt;1&gt; return self.total() - discount def __repr__(self): fmt = '&lt;Order total: &#123;:.2f&#125; due: &#123;:.2f&#125;&gt;' return fmt.format(self.total(), self.due())# &lt;2&gt;def fidelity_promo(order): # &lt;3&gt; """5% discount for customers with 1000 or more fidelity points""" return order.total() * .05 if order.customer.fidelity &gt;= 1000 else 0def bulk_item_promo(order): """10% discount for each LineItem with 20 or more units""" discount = 0 for item in order.cart: if item.quantity &gt;= 20: discount += item.total() * .1 return discountdef large_order_promo(order): """7% discount for orders with 10 or more distinct items""" distinct_items = &#123;item.product for item in order.cart&#125; if len(distinct_items) &gt;= 10: return order.total() * .07 return 0# END STRATEGY Sample usage of Order class with promotions as functions1234567&gt;&gt;&gt; joe = Customer('John Doe', 0) &gt;&gt;&gt; ann = Customer('Ann Smith', 1100) &gt;&gt;&gt; cart = [LineItem('banana', 4, .5), ... LineItem('apple', 10, 1.5), ... LineItem('watermellon', 5, 5.0)] &gt;&gt;&gt; Order(joe, cart, fidelity_promo) &lt;Order total: 42.00 due: 42.00&gt; best_promo1234promos=[fidelity_promo, bulk_item_promo, large_order_promo]def best_promo(order): return max(promo(order) for promo in promos) globals()globals()Return a dictionary representing the current global symbol table. This is always the dictionary of the current module (inside a function or method, this is the module where it is defined, not the module from which it is called). 123promos=[globals()[name] for name in globals() if name.endswith('_promo') and name != 'best_promo']def best_promo(order): return max(promo(order) for promo in promos) create a module and put all the strategy functions there, except for best_promoThe list of strategy functions is built by introspection of a separate module called promotions. 1234promos=[func for name, func in inspect.getmembsers(promotions, inspect.isfunction)]def best_promo(order): return max(promo(order) for promo in promos) The function inspect.getmembers returns the attributes of an object—in this case, the promotions module—optionally filtered by a predicate (a boolean function). We use inspect.isfunction to get only the functions from the module.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C05_functional programming]]></title>
    <url>%2F2018%2F04%2F22%2FC05-functional-programming%2F</url>
    <content type="text"><![CDATA[The operator Module123&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def fact(n):... return reduce(lambda a,b : a*b, ranage(1,n+1)) To save you the trouble of writing trivial anonymous functions like lambda a, b:a*b, the operator module provides function equivalents for dozens of arithmetic operators.123&gt;&gt;&gt; from operator import mul&gt;&gt;&gt; def fact(n):... return reduce(mul, range(1,n+1)) itemgetter and attrgetteritemgetter itemgetter(1) does the same as lambda fields: fields[1]: create a function that, given a collection, returns the item at index 1. Because itemgetter uses the [ ] operator, it supports not only sequences but also mappings andany class that implements __getitem__. 1234567891011121314151617&gt;&gt;&gt; metro_data = [... ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)),... ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)),... ]&gt;&gt;&gt; from operator import itemgetter&gt;&gt;&gt; for city in sorted(metro_data, key=itemgetter(1)):... print(city)('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889))('Tokyo', 'JP', 36.933, (35.689722, 139.691667))# pass multiple index arguments to itemgetter, the function it builds will returntuples with the extracted values&gt;&gt;&gt; cc_name = itemgetter(1, 0)&gt;&gt;&gt; for city in metro_data:... print(cc_name(city))('JP', 'Tokyo')('IN', 'Delhi NCR') attrgetter attrgetter creates functions to extract object attributes by name. If you pass attrgetter severalattribute names as arguments, it also returns a tuple of values. In addition, if any argument name contains a . (dot), attrgetter navigates through nested objects to retrieve the attribute.123456789101112131415161718192021222324&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; LatLong = namedtuple('LatLong', 'lat long') #&gt;&gt;&gt; Metropolis = namedtuple('Metropolis', 'name cc pop coord') # &gt;&gt;&gt; metro_areas = [Metropolis(name, cc, pop, LatLong(lat, long)) #... for name, cc, pop, (lat, long) in metro_data]&gt;&gt;&gt; metro_areas[0]Metropolis(name='Tokyo', cc='JP', pop=36.933, coord=LatLong(lat=35.689722,long=139.691667))&gt;&gt;&gt; metro_areas[0].coord.lat #Reach into element metro_areas[0] to get its latitude.35.689722&gt;&gt;&gt; from operator import attrgetter&gt;&gt;&gt; name_lat = attrgetter('name', 'coord.lat') #Define an attrgetter to retrieve the name and the coord.lat nested attribute&gt;&gt;&gt;&gt;&gt;&gt; for city in sorted(metro_areas, key=attrgetter('coord.lat')): # Use attrgetter again to sort list of cities by latitude.... print(name_lat(city)) #...('Sao Paulo', -23.547778)('Mexico City', 19.433333)('Delhi NCR', 28.613889)('Tokyo', 35.689722)('New York-Newark', 40.808611) methodcallermethodcaller creates a function on the fly. The function it creates calls a method by name on theobject given as argument. 12345678&gt;&gt;&gt; from operator import methodcaller&gt;&gt;&gt; s = 'The time has come'&gt;&gt;&gt; upcase = methodcaller('upper')&gt;&gt;&gt; upcase(s)'THE TIME HAS COME'&gt;&gt;&gt; hiphenate = methodcaller('replace', ' ', '-')&gt;&gt;&gt; hiphenate(s)'The-time-has-come' functools.partialfunctools.partial is a higher-order function that allows partial application of a function. Given a function, a partial application produces a new callable with some of the arguments of the original function fixed. partial takes a callable as first argument, followed by an arbitrary number of positional and keywordarguments to bind. 1234567&gt;&gt;&gt; from operator import mul&gt;&gt;&gt; from functools import partial&gt;&gt;&gt; triple=partial(mul, 3)&gt;&gt;&gt; triple(7)21&gt;&gt;&gt; list(map(triple, range(1,10)))[3, 6, 9, 12, 15, 18, 21, 24, 27] 1234567891011&gt;&gt;&gt; tag&lt;function tag at 0x03DFA300&gt;&gt;&gt;&gt; picture=partial(tag, 'img', cls='pic-frame')&gt;&gt;&gt; picturefunctools.partial(&lt;function tag at 0x03DFA300&gt;, 'img', cls='pic-frame')&gt;&gt;&gt; picture.func&lt;function tag at 0x03DFA300&gt;&gt;&gt;&gt; picture.args('img',)&gt;&gt;&gt; picture.keywords&#123;'cls': 'pic-frame'&#125; The functools.partialmethod function (new in Python 3.4) does the same job as partial, but isdesigned to work with methods.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C05_functions]]></title>
    <url>%2F2018%2F04%2F22%2FC05-functions%2F</url>
    <content type="text"><![CDATA[Higher-Order FunctionsReplacements for map, filter, and reduceFunctional languages commonly offer the map, filter, and reduce higher-order functions(sometimes with different names). A listcomp or a genexp does the job of map and filtercombined, but is more readable. 12345678&gt;&gt;&gt; list(map(fact, range(6)))[1, 1, 2, 6, 24, 120]&gt;&gt;&gt; [fact(n) for n in range(6)][1, 1, 2, 6, 24, 120]&gt;&gt;&gt; list(map(factorial, filter(lambda n: n % 2, range(6))))[1, 6, 120]&gt;&gt;&gt; [factorial(n) for n in range(6) if n % 2][1, 6, 120] map and filter return generators—a form of iterator—so their direct substitute is now a generator expression . The reduce function was demoted from a built-in in Python 2 to the functools module in Python 3.123456&gt;&gt;&gt; from functools import reduce #Starting with Python 3.0, reduce is not a built-in&gt;&gt;&gt; from operator import add&gt;&gt;&gt; reduce(add, range(100))4950&gt;&gt;&gt; sum(range(100)) Other reducing built-ins are all and any:all(iterable)Returns True if every element of the iterable is truthy; all([ ]) returns True.any(iterable)Returns True if any element of the iterable is truthy; any([ ]) returns False. Anonymous FunctionsThe best use of anonymous functions is in the context of an argument list. 12&gt;&gt;&gt; fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']&gt;&gt;&gt; sorted(fruits, key=lambda word: word[::-1]) Callable ObjectsThe call operator (i.e., ()) may be applied to other objects beyond user-defined functions. To determinewhether an object is callable, use the callable() built-in function. User-Defined Callable TypesArbitrary Python objects may also be made to behave like functions. Implementing a __call__instance method is all it takes. 123456789101112131415import randomclass BingoCage: def __init__(self, items): self._items=list(items) random.shuffle(self._items) def pick(self): try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): return self.pick() A class implementing *__call__**is an easy way to create function-like objects that havesome internal state that must be kept across invocations. An example is a decorator. Decorators must befunctions, but it is sometimes convenient to be able to “remember” something between calls of thedecorator. Function Introspection123456&gt;&gt;&gt; dir(factorial)['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__'] __dict__Like the instances of a plain user-defined class, a function uses the__dict__attribute to store userattributes assigned to it. Listing attributes of functions that don’t exist in plain instances1234567&gt;&gt;&gt; class C: pass #&gt;&gt;&gt; obj = C() #&gt;&gt;&gt; def func(): pass #&gt;&gt;&gt; sorted(set(dir(func)) - set(dir(obj))) #['__annotations__', '__call__', '__closure__', '__code__', '__defaults__','__get__', '__globals__', '__kwdefaults__', '__name__', '__qualname__'] Positional and Keyword-Only ParametersUsing* and ** to “explode” iterables and mappings into separate arguments whenwe call a function. __defaults__ 123456789101112131415def clip(text, max_len=80): """Return text clipped at the last space before or after max_len """ end = None if len(text) &gt; max_len: space_before = text.rfind(' ', 0, max_len) if space_before &gt;= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after &gt;= 0: end = space_after if end is None: # no spaces were found end = len(text) return text[:end].rstrip() The values of __defaults__, __code__.co_varnames, and__code__.co_argcount for the clip function:123456789&gt;&gt;&gt; from clip import clip&gt;&gt;&gt; clip.__defaults__(80,)&gt;&gt;&gt; clip.__code__ # doctest: +ELLIPSIS&lt;code object clip at 0x...&gt;&gt;&gt;&gt; clip.__code__.co_varnames(&apos;text&apos;, &apos;max_len&apos;, &apos;end&apos;, &apos;space_before&apos;, &apos;space_after&apos;)&gt;&gt;&gt; clip.__code__.co_argcount2 Extracting the function signature:123456789101112&gt;&gt;&gt; from clip import clip&gt;&gt;&gt; from inspect import signature&gt;&gt;&gt; sig = signature(clip)&gt;&gt;&gt; sig # doctest: +ELLIPSIS&lt;inspect.Signature object at 0x...&gt;&gt;&gt;&gt; str(sig)'(text, max_len=80)'&gt;&gt;&gt; for name, param in sig.parameters.items():... print(param.kind, ':', name, '=', param.default)...POSITIONAL_OR_KEYWORD : text = &lt;class 'inspect._empty'&gt;POSITIONAL_OR_KEYWORD : max_len = 80 The kind attribute holds one of five possible values from the _ParameterKind class:POSITIONAL_OR_KEYWORDA parameter that may be passed as a positional or as a keyword argument (most Python functionparameters are of this kind).VAR_POSITIONALA tuple of positional parameters.VAR_KEYWORDA dict of keyword parameters.KEYWORD_ONLYA keyword-only parameter (new in Python 3).POSITIONAL_ONLYA positional-only parameter; currently unsupported by Python function declaration syntax. inspect.Signature 12345678910111213141516171819def tag(name,*content, cls=None, **attrs): pass&gt;&gt;&gt; import inspect&gt;&gt;&gt; sig = inspect.signature(tag)&gt;&gt;&gt; my_tag = &#123;'name': 'img', 'title': 'Sunset Boulevard',... 'src': 'sunset.jpg', 'cls': 'framed'&#125;&gt;&gt;&gt; bound_args = sig.bind(**my_tag)&gt;&gt;&gt; bound_args&lt;inspect.BoundArguments object at 0x...&gt;&gt;&gt;&gt; for name, value in bound_args.arguments.items(): #Iterate over the items in bound_args.arguments, which is an OrderedDict, to display the names and # values of the arguments.... print(name, '=', value)...name = imgcls = framedattrs = &#123;'title': 'Sunset Boulevard', 'src': 'sunset.jpg'&#125;&gt;&gt;&gt; del my_tag['name']&gt;&gt;&gt; bound_args = sig.bind(**my_tag)Traceback (most recent call last): Function AnnotationsEach argument in the function declaration may have an annotation expression preceded by :. If there is a default value, the annotation goes between the argument name and the = sign. To annotate the return value, add -&gt; and another expression between the ) and the : at the tail of the function declaration. The expressions may be of any type. 12345678# clip_annot.pydef clip(text:str, max_len:'int &gt; 0' =80) -&gt;str: end=None if len(text) &gt; max_len: pass&gt;&gt;&gt; from clip_annot import clip&gt;&gt;&gt; clip.__annotations__&#123;'text': &lt;class 'str'&gt;, 'max_len': 'int &gt; 0', 'return': &lt;class 'str'&gt;&#125; Extracting annotations from the function signatureThe signature function returns a Signature object, which has a return_annotation attribute and aparameters dictionary mapping parameter names to Parameter objects. Each Parameter object has itsown annotation attribute. 12345678910&gt;&gt;&gt; from clip_annot import clip&gt;&gt;&gt; from inspect import signature&gt;&gt;&gt; sig = signature(clip)&gt;&gt;&gt; sig.return_annotation&lt;class 'str'&gt;&gt;&gt;&gt; for param in sig.parameters.values():... note = repr(param.annotation).ljust(13)... print(note, ':', param.name, '=', param.default)&lt;class 'str'&gt; : text = &lt;class 'inspect._empty'&gt;'int &gt; 0' : max_len = 80]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C04_bytes, bytesarray, struct module, memory views]]></title>
    <url>%2F2018%2F04%2F22%2FC04-bytes-bytesarray-struct-module-memory-views%2F</url>
    <content type="text"><![CDATA[The Unicode standard explicitly separates the identity of characters from specific byte representations: The identity of a character The actual bytes that represent a character depend on the encoding in use. Although binary sequences are really sequences of integers, their literal notation reflects the fact that ASCII text is often embedded in them. Therefore, three different displays are used, depending on each byte value: For bytes in the printable ASCII range—from space to ~—the ASCII character itself is used. For bytes corresponding to tab, newline, carriage return, and \, the escape sequences \t, \n, \r, and \ are used. For every other byte value, a hexadecimal escape sequence is used (e.g., \x00 is the null byte). Binary sequences have a class method that str doesn’t have, called fromhex, which builds a binary sequence by parsing pairs of hex digits optionally separated by spaces:12&gt;&gt;&gt; bytes.fromhex('31 4B CE A9')b'1K\xce\xa9' Building a binary sequence from a buffer-like object is a low-level operation that may involve type casting.12345&gt;&gt;&gt; import array&gt;&gt;&gt; numbers = array.array('h', [-2, -1, 0, 1, 2])&gt;&gt;&gt; octets = bytes(numbers)&gt;&gt;&gt; octetsb'\xfe\xff\xff\xff\x00\x00\x01\x00\x02\x00' Structs and Memory ViewsThe struct module provides functions to parse packed bytes into a tuple of fields of different types and to perform the opposite conversion, from a tuple into packed bytes. Struct is used with bytes, bytearray, and memoryview objects. 123&gt;&gt;&gt; import struct&gt;&gt;&gt; fmt = '&lt;3s3sHH' #struct format: &lt; little-endian; 3s3s two sequences of 3 bytes; HH two 16-bitintegers. 123456789101112&gt;&gt;&gt; with open('filter.gif', 'rb') as fp:... img = memoryview(fp.read()) #...&gt;&gt;&gt; header = img[:10] # another memoryview by slicing the first one; no bytes are copied here&gt;&gt;&gt; bytes(header) #Convert to bytes for display only; 10 bytes are copied hereb'GIF89a+\x02\xe6\x00'&gt;&gt;&gt; struct.unpack(fmt, header) #Unpack memoryview into tuple of: type, version, width, and height(b'GIF', b'89a', 555, 230)&gt;&gt;&gt; del header #Delete references to release the memory associated with the memoryviewinstances&gt;&gt;&gt; del img Discover the Encoding of a Byte SequenceIf you omit the encoding argument when opening a file, the default is given by locale.getpreferredencoding() (‘cp1252’ on Windows). It is the default for opening text files and for sys.stdout/stdin/stderr when they are redirected to files. The encoding of sys.stdout/stdin/stderr is given by the PYTHONIOENCODING environment variable, if present, otherwise it is either inherited from the console or defined by locale.getpreferredencoding() if the output/input is redirected to/from a file. sys.getdefaultencoding() is used internally by Python to convert binary data to/from str; this happens less often in Python 3, but still happens. sys.getfilesystemencoding() is used to encode/decode filenames (not file contents). It is used when open() gets a str argument for the filename; if the filename is given as a bytes argument, it is passed unchanged to the OS API. The Python Unicode HOWTO says: “on Windows, Python uses the name mbcs to refer to whatever the currently configured encoding is.” The acronym MBCS stands for Multi Byte Character Set, which for Microsoft are the legacy variable-width encodings like gb2312 or Shift_JIS, but not UTF-8.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C03_set, hash tables]]></title>
    <url>%2F2018%2F04%2F22%2FC03-set-hash-tables%2F</url>
    <content type="text"><![CDATA[set, forzensetA set is a collection of unique objects. A basic use case is removing duplication: 12345&gt;&gt;&gt; l = ['spam', 'spam', 'eggs', 'spam']&gt;&gt;&gt; set(l)&#123;'eggs', 'spam'&#125;&gt;&gt;&gt; list(set(l))['eggs', 'spam'] There is no special syntax to represent frozenset literals—they must be created by calling the constructor. 12&gt;&gt;&gt; frozenset(range(10))frozenset(&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125;) There’s no literal notation for the empty set, so we must remember to write set(). hashA hash table is a sparse array (i.e., an array that always has empty cells). In standard data structure texts,the cells in a hash table are often called “buckets.” In a dict hash table, there is a bucket for each item, andit contains two fields: a reference to the key and a reference to the value of the item. Because all bucketshave the same size, access to an individual bucket is done by offset. To put an item in a hash table, the first step is to calculate the hash value of the item key, which is donewith the hash() built-in function. Hashes and equalityThe hash() built-in function works directly with built-in types and falls back to calling __hash__ for user-defined types. If two objects compare equal, their hash values must also be equal, otherwise the hashtable algorithm does not work. To be effective as hash table indexes, hash values should scatter around the index space as much aspossible. This means that, ideally, objects that are similar but not equal should have hash values that differwidely. hash table algorithmTo fetch the value at my_dict[search_key], Python calls hash(search_key) to obtain the hash value ofsearch_key and uses the least significant bits of that number as an offset to look up a bucket in the hashtable (the number of bits used depends on the current size of the table). If the found bucket is empty,KeyError is raised.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[re module_compile, finditer, group, match]]></title>
    <url>%2F2018%2F04%2F22%2Fre-module-compile-finditer-group-match%2F</url>
    <content type="text"><![CDATA[使用 re 模块有两种方式： 使用 re.compile 函数生成一个 Pattern 对象，然后使用 Pattern 对象的一系列方法对文本进行匹配查找； 直接使用 re.match, re.search 和 re.findall 等函数直接对文本匹配查找。 re 模块的一般使用步骤如下： 使用 compile 函数将正则表达式的字符串形式编译为一个 Pattern 对象 通过 Pattern 对象提供的一系列方法对文本进行匹配查找，获得匹配结果（一个 Match 对象） 最后使用 Match 对象提供的属性和方法获得信息，根据需要进行其他的操作 Python 的正则匹配默认是贪婪匹配。 compile12import repattern=re.compile(r'\w+') pattern的常用方法： match 方法 search 方法 findall 方法 finditer 方法 split 方法 sub 方法 subn 方法 matchmatch 方法用于查找字符串的头部（也可以指定起始位置），它是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果。123456789101112&gt;&gt;&gt; pattern=re.compile(r'\d+')&gt;&gt;&gt; m=pattern.match(''one12twothree34four', 3, 10') #从'1'的位置开始匹配，正好匹配&gt;&gt;&gt; print(m) # 返回一个 Match 对象&lt;_sre.SRE_Match object at 0x10a42aac0&gt;&gt;&gt;&gt; m.group(0) # 可省略 0'12'&gt;&gt;&gt; m.start(0) # 可省略 03&gt;&gt;&gt; m.end(0) # 可省略 05&gt;&gt;&gt; m.span(0) # 可省略 0(3, 5) 当匹配成功时返回一个 Match 对象，其中： group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)； start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0； end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0； span([group]) 方法返回 (start(group), end(group))。 123456&gt;&gt;&gt; pattern = re.compile(r'([a-z]+) ([a-z]+)', re.I) # re.I 表示忽略大小写&gt;&gt;&gt; m = pattern.match('Hello World Wide Web')&gt;&gt;&gt; m.group(0) # 返回匹配成功的整个子串'Hello World'&gt;&gt;&gt; m.groups() # 等价于 (m.group(1), m.group(2), ...)('Hello', 'World') finditerfinditer 方法的行为跟 findall 的行为类似，也是搜索整个字符串，获得所有匹配的结果。但它返回一个顺序访问每一个匹配结果（Match 对象）的迭代器12for match in pattern.finditer(hello 234 ref'): print(match.group(), m1.span())]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C03_Generic Mapping Types, hashable]]></title>
    <url>%2F2018%2F04%2F22%2FC03-Generic-Mapping-Types-hashable%2F</url>
    <content type="text"><![CDATA[hashableAn object is hashable if it has a hash value which never changes during its lifetime (it needs a hash()method), and can be compared to other objects (it needs an eq() method). Hashable objects whichcompare equal must have the same hash value.The atomic immutable types (str, bytes, numeric types) are all hashable. A frozen set is always hashable,because its elements must be hashable by definition. A tuple is hashable only if all its items are hashable. User-defined types are hashable by default because their hash value is their id() and they all compare notequal. If an object implements a custom eq that takes into account its internal state, it may be hashable only if all its attributes are immutable. ways to build a dict1234567&gt;&gt;&gt; a = dict(one=1, two=2, three=3)&gt;&gt;&gt; b = &#123;'one': 1, 'two': 2, 'three': 3&#125;&gt;&gt;&gt; c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))&gt;&gt;&gt; d = dict([('two', 2), ('one', 1), ('three', 3)])&gt;&gt;&gt; e = dict(&#123;'three': 3, 'one': 1, 'two': 2&#125;)&gt;&gt;&gt; a == b == c == d == eTrue dict comprehension A dictcomp builds a dict instance by producing key:value pair from any iterable. dict.setdefault12345678910111213141516import sysimport reWORD_RE = re.compile('\w+')index = &#123;&#125;with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) # this is ugly; coded like this to make a point occurrences = index.get(word, []) occurrences.append(location) index[word] = occurrences for word in sorted(index, key=str.upper): print(word, index[word]) 123456789with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) index.setdefault(word, []).append(location) #Get the list of occurrences for word, or set it to [ ] if not found; setdefault returns the value, so it can be #updated without requiring a second search. collections.defaultdictA defaultdict is configured to create items on demand whenever a missing key is searched. When instantiating a defaultdict, you provide a callable that is used to produce a default value whenever__getitem__ is passed a nonexistent key argument. given an empty defaultdict created as dd = defaultdict(list), if ‘new-key’ is not in dd, the expressiondd[‘new-key’] does the following steps: Calls list() to create a new list. Inserts the list into dd using ‘new-key’ as key. Returns a reference to that list 123456789101112131415161718import sysimport reimport collectionsword_re=re.compile('\w+')index=collections.defaultdict(list) #Create a defaultdict with the list constructor as default_factory.If no default_factory is provided, the usual KeyError is raised for missing keys.with open(sys.argv[1],encoding='utf-8') as fp: for line_no, line in enumerate(fp,1): for match in word_re.finditer(line): word=match.group() column_no=match.start()+1 location=(line_no,column_no) index[word].append(location) #If word is not initially in the index, the default_factory is called to produce the missing value, which in this #case is an empty list that is then assigned to index[word] and returned, so the .append(location) #operation always succeeds. __missing__If you subclass dict and provide a __missing__ method, the standard dict.getitemwill call itwhenever a key is not found, instead of raising KeyError. The __missing__ method is just called by __getitem__ (i.e., forthe d[k] operator). The presence of a __missing__ method has no effect on the behavior of other methods that look up keys, such as get or__contains__ (which implements the in operator). This is why the default_factory of defaultdict worksonly with__getitem__, 12345678910111213141516class StrKeyDict0(dict): def __missing__(self,key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def get(self,key,default=None): try: return self[key] #The get method delegates to __getitem__ by using the self[key] notation; that gives the opportunity for our __missing__ to act. except KeyError: return default def __contains__(self,key): #we do not check for the key in the usual Pythonic way—k in my_dict—becausestr(key) in self would recursively call __contains__. We avoid this by explicitly looking up the key in self.keys(). return key in self.keys() or str(key) in self.keys() collections.OrderedDict collections.ChainMap collections.Counter collections.UserDictUserDict it’s preferable to subclass from UserDict rather than from dict is that the built-in has someimplementation shortcuts that end up forcing us to override methods that we can just inherit fromUserDict with no problems. Note that UserDict does not inherit from dict, but has an internal dict instance, called data, which holdsthe actual items. This avoids undesired recursion when coding special methods like __setitem__, andsimplifies the coding of __contains__.1234567891011class StrKeyDict(collections.UserDict): def __missing__(self,key): if isinstance(key, str): raise KeyError(key) return self[str(key)] def __contains__(self, key): return str(key) in self.data def __setitem__(self, key, item): self.data[str(key)] = item UserDict subclasses MutableMapping, the remaining methods that make StrKeyDict a full-fledgedmapping are inherited from UserDict, MutableMapping, or Mapping. The latter have several usefulconcrete methods, in spite of being abstract base classes (ABCs). The following methods are worth noting: MutableMapping.update This powerful method can be called directly but is also used by __init__ to load the instance from other mappings, from iterables of (key, value) pairs, and keyword arguments. Because it uses self[key] = value to add items, it ends up calling our implementation of __setitem__. Mapping.get In StrKeyDict0 (Example 3-7), we had to code our own get to obtain results con‐sistent with getitem, but in Example 3-8 we inherited Mapping.get, which isimplemented exactly like StrKeyDict0.get (see Python source code). MappingProxyTypeThe types module provides a wrapper class called MappingProxyType, which, given a mapping, returns amappingproxy instance that is a read-only but dynamic view of the original mapping. This means thatupdates to the original mapping can be seen in the mappingproxy, but changes cannot be made throughit. 12345678910111213141516&gt;&gt;&gt; from types import MappingProxyType&gt;&gt;&gt; d = &#123;1: 'A'&#125;&gt;&gt;&gt; d_proxy = MappingProxyType(d)&gt;&gt;&gt; d_proxymappingproxy(&#123;1: 'A'&#125;)&gt;&gt;&gt; d_proxy[1] # Items in d can be seen through d_proxy.'A'&gt;&gt;&gt; d_proxy[2] = 'x' # Changes cannot be made through d_proxy.Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: 'mappingproxy' object does not support item assignment&gt;&gt;&gt; d[2] = 'B'&gt;&gt;&gt; d_proxy # d_proxy is dynamic: any change in d is reflectedmappingproxy(&#123;1: 'A', 2: 'B'&#125;)&gt;&gt;&gt; d_proxy[2]'B']]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C_deque]]></title>
    <url>%2F2018%2F04%2F22%2FC-deque%2F</url>
    <content type="text"><![CDATA[Inserting and removing from the left of a list (the 0-index end) is costly because the entire list must be shifted. The class collections.deque is a thread-safe double-ended queue designed for fast inserting and removingfrom both ends. It is also the way to go if you need to keep a list of “last seen items” or something like that, because a deque can be bounded—i.e., created with a maximum length—and then, when it is full, itdiscards items from the opposite end when you append new ones.The append and popleft operations are atomic, so deque is safe to use as a LIFO queue in multithreadedapplications without the need for using locks.12345678910111213141516171819&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; dq = deque(range(10), maxlen=10)&gt;&gt;&gt; dqdeque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.rotate(3)&gt;&gt;&gt; dqdeque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10)&gt;&gt;&gt; dq.rotate(-4)&gt;&gt;&gt; dqdeque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10)&gt;&gt;&gt; dq.appendleft(-1) #Appending to a deque that is full discards items from the other end&gt;&gt;&gt; dqdeque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.extend([11, 22, 33])&gt;&gt;&gt; dqdeque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10)&gt;&gt;&gt; dq.extendleft([10, 20, 30, 40])&gt;&gt;&gt; dqdeque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10)]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_Array, Memory Views]]></title>
    <url>%2F2018%2F04%2F22%2FC02-Array-Memory-Views%2F</url>
    <content type="text"><![CDATA[An array does not actually hold full-fledged float objects, but only the packed bytes representing theirmachine values—just like an array in the C language. On the other hand, if you are constantly adding andremoving items from the ends of a list as a FIFO or LIFO data structure, a deque (double-ended queue)works faster. array.arrayIf the list will only contain numbers, an array.array is more efficient than a list: it supports all mutablesequence operations (including .pop, .insert, and .extend), and additional methods for fast loading andsaving such as .frombytes and .tofile. When creating an array, you provide a typecode,A letter to determine the underlying C type used to store each item in the array. For example, b is thetypecode for signed char. If you create an array(‘b’), then each item will be stored in a single byte andinterpreted as an integer from –128 to 127. For large sequences of numbers, this saves a lot of memory.And Python will not let you put any number that does not match the type for the array.12345678910111213141516&gt;&gt;&gt; from array import array&gt;&gt;&gt; from random import random&gt;&gt;&gt; floats = array('d', (random() for i in range(10**7)))&gt;&gt;&gt; floats[-1]0.07802343889111107&gt;&gt;&gt; fp = open('floats.bin', 'wb')&gt;&gt;&gt; floats.tofile(fp)&gt;&gt;&gt; fp.close()&gt;&gt;&gt; floats2 = array('d') &gt;&gt;&gt; fp = open('floats.bin', 'rb')&gt;&gt;&gt; floats2.fromfile(fp, 10**7)&gt;&gt;&gt; fp.close()&gt;&gt;&gt; floats2[-1]0.07802343889111107&gt;&gt;&gt; floats2 == floatsTrue As of Python 3.4, the array type does not have an in-place sort method like list.sort(). If you need to sortan array, use the sorted function to rebuild it sorted:1a=array.array(typecode, sorted(a)) memoryviewA memoryview is essentially a generalized NumPy array structure in Python itself (without the math). Itallows you to share memory between data-structures (things like PIL images, SQLlite databases, NumPyarrays, etc.) without first copying. This is very important for large data sets. memoryview.cast method lets you change the way multiple bytes are read or written as units withoutmoving bits around (just like the C cast operator). memoryview.cast returns yet another memoryviewobject, always sharing the same memory]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_list.sort and the sorted Built-In Function, bisect]]></title>
    <url>%2F2018%2F04%2F22%2FC02-list-sort-and-the-sorted-Built-In-Function-bisect%2F</url>
    <content type="text"><![CDATA[list.sort and sortedThe list.sort method sorts a list in place—that is, without making a copy. It returns None to remind us that itchanges the target object, and does not create a new list. This is an important Python API convention:functions or methods that change an object in place should return None to make it clear to the caller thatthe object itself was changed, and no new object was created.The built-in function sorted creates a new list and returns it. In fact, itaccepts any iterable object as anargument, including immutable sequences and generators. Regardless of the type of iterable given to sorted, it always returns a newly created list Both list.sort and sorted take two optional, keyword-only arguments:reverse: If True, the items are returned in descending order (i.e., by reversing the comparison of the items). The default is False. key: A one-argument function that will be applied to each item to produce its sorting key. For example, when sorting a list of strings, key=str.lower can be used to perform a case-insensitive sort, and key=len will sort the strings by character length. The default is the identity function (i.e., the items themselves are compared).bisectThe bisect module offers two main functions—bisect and insort. bisect(haystack, needle) does a binary search for needle in haystack—which must be a sorted sequence.You could use the result of bisect(haystack, needle) as the index argument to haystack.insert(index, needle)—however, using insort does both steps, and is faster. bisect finds insertion points for items in a sorted sequencebisect_right returns an insertion point after the existing item, and bisect_left returns the position of theexisting item, so insertion would occur before it.1234567891011121314151617181920212223242526import bisectimport sysHAYSTACK=[1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30]NEEDLES=[0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31]ROW_FMT='&#123;0:2d&#125; @ &#123;1:2d&#125; &#123;2&#125;&#123;0:&lt;2d&#125;'def demo(bisect_fn): for needle in reversed(NEEDLES): positioin=bisect_fn(HAYSTACK, needle) #Use the chosen bisect function to get the insertion point. offset=positioin * ' |' print(ROW_FMT.format(needle, positioin, offset))if __name__=='__main__': if sys.argv[-1] =='left': bisect_fn=bisect.bisect_left else: bisect_fn=bisect.bisect print('DEMO:', bisect_fn.__name__) print('haystack -&gt;',' '.join('%2d'% n for n in HAYSTACK )) demo(bisect_fn) 1234567&gt;&gt;&gt; import bisect&gt;&gt;&gt; def grade(score, breakpoints=[60,70,80,90],grades='FDCBA'):... i=bisect.bisect(breakpoints, score)... return grades[i]... &gt;&gt;&gt; [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]['F', 'A', 'C', 'C', 'B', 'A', 'A'] Inserting with bisect.insortinsort(seq, item) inserts item into seq so as to keep seq in ascending order12345678910111213141516171819import bisectimport randomSIZE=7random.seed(1729)my_list=[]for i in range(SIZE): new_item = random.randrange(SIZE*2) bisect.insort(my_list, new_item) print('%2d -&gt;' % new_item, my_list)#10 -&gt; [10]#0 -&gt; [0, 10]#6 -&gt; [0, 6, 10]#8 -&gt; [0, 6, 8, 10]#7 -&gt; [0, 6, 7, 8, 10]#2 -&gt; [0, 2, 6, 7, 8, 10]#10 -&gt; [0, 2, 6, 7, 8, 10, 10]]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_Sequence Assignment +=, *=]]></title>
    <url>%2F2018%2F04%2F22%2FC02-Sequence-Assignment%2F</url>
    <content type="text"><![CDATA[#The augmented assignment operators += and *= behave very differently depending on the first operand. The special method that makes += work is iadd (for “in-place addition”). However, if iadd is notimplemented, Python falls back to calling add.If a implements iadd, a += b will be called. In the case of mutable sequences (e.g., list, bytearray,array.array), a will be changed in place (i.e., the effect will be similar to a.extend(b)). However, when a doesnot implement iadd, the expression a += b has the same effect as a = a + b: the expression a + b isevaluated first, producing a new object, which is then bound to a. In general, for mutable sequences, it is a good bet that iadd is implemented and that += happens inplace. For immutable sequences, clearly there is no way for that to happen.1234567891011121314&gt;&gt;&gt; l = [1, 2, 3]&gt;&gt;&gt; id(l)4311953800&gt;&gt;&gt; l *= 2&gt;&gt;&gt; l[1, 2, 3, 1, 2, 3]&gt;&gt;&gt; id(l)4311953800&gt;&gt;&gt; t = (1, 2, 3)&gt;&gt;&gt; id(t)4312681568&gt;&gt;&gt; t *= 2&gt;&gt;&gt; id(t)4301348296]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_Slice Objects]]></title>
    <url>%2F2018%2F04%2F22%2FC02-Slice-Objects%2F</url>
    <content type="text"><![CDATA[The notation a :b :c is only valid within [ ] when used as the indexing or subscript operator, and it produces aslice object: slice(a, b, c).To evaluate the expression seq[start:stop:step], Python calls seq.getitem(slice(start, stop, step)). Assign to slices12345678910&gt;&gt;&gt; l=list(range(10))&gt;&gt;&gt; l[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; l[2:5]=[20,30] #When the target of the assignment is a slice, the right side must be an iterable object, even if it has just one item.&gt;&gt;&gt; l[0, 1, 20, 30, 5, 6, 7, 8, 9]&gt;&gt;&gt; del l[5:7]&gt;&gt;&gt; l[0, 1, 20, 30, 5, 8, 9] Building Lists of Lists1123456&gt;&gt;&gt; board = [['_'] * 3 for i in range(3)]&gt;&gt;&gt; board[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]&gt;&gt;&gt; board[1][2] = 'X'&gt;&gt;&gt; board[['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] Equivalent to:12345678910&gt;&gt;&gt; board = []&gt;&gt;&gt; for i in range(3):... row = ['_'] * 3 #... board.append(row)...&gt;&gt;&gt; board[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]&gt;&gt;&gt; board[2][0] = 'X'&gt;&gt;&gt; board #[['_', '_', '_'], ['_', '_', '_'], ['X', '_', '_']] 2123456&gt;&gt;&gt; weird_board = [['_'] * 3] * 3&gt;&gt;&gt; weird_board[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]&gt;&gt;&gt; weird_board[1][2] = 'O'&gt;&gt;&gt; weird_board[['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']] Equivalent to:1234row = ['_'] * 3board = []for i in range(3): board.append(row)]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_Tuple unpacking, namedtuple]]></title>
    <url>%2F2018%2F04%2F22%2FC02-Tuple-unpacking-namedtuple%2F</url>
    <content type="text"><![CDATA[Tuple unpacking works with any iterable object. The only requirement is that the iterable yields exactly oneitem per variable in the receiving tuple, unless you use a star (*) to capture excess items. 123456789101112&gt;&gt;&gt; t=(20,8)&gt;&gt;&gt; divmod(t)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: divmod expected 2 arguments, got 1&gt;&gt;&gt; divmod(*t)(2, 4)&gt;&gt;&gt; import os&gt;&gt;&gt; _,filename=os.path.split('/hom/lubi/.ssh/if.pub')&gt;&gt;&gt; filename'if.pub' use * to grab excess items123456&gt;&gt;&gt; a,b,*rest=range(5)&gt;&gt;&gt; a,b,rest(0, 1, [2, 3, 4])&gt;&gt;&gt; *head,b,c=range(5)&gt;&gt;&gt; head,b,c([0, 1, 2], 3, 4) namedtuple Two parameters are required to create a named tuple: a class name and a list of field names, which can be given as an iterable of strings or as a single spacedelimited string. Data must be passed as positional arguments to the constructor (in contrast, the tuple constructor takes a single iterable). You can access the fields by name or position. 12345678910&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; City = namedtuple('City', 'name country population coordinates')&gt;&gt;&gt; tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))&gt;&gt;&gt; tokyoCity(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722,139.691667))&gt;&gt;&gt; tokyo.population36.933&gt;&gt;&gt; tokyo[1]'JP' _fields is a tuple with the field names of the class. _make() allow you to instantiate a named tuple from an iterable; City(*delhi_data) would do the same. _asdict() returns a collections.OrderedDict built from the named tuple instance. 12345678910&gt;&gt;&gt; City._fields('name', 'country', 'population', 'coordinates')&gt;&gt;&gt; LatLong = namedtuple('LatLong', 'lat long')&gt;&gt;&gt; delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889))&gt;&gt;&gt; delhi = City._make(delhi_data)&gt;&gt;&gt; delhi._asdict()OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population',21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))])&gt;&gt;&gt; for key, value in delhi._asdict().items(): print(key + ':', value)]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_Generate Expressions]]></title>
    <url>%2F2018%2F04%2F22%2FC02-Generate-Expressions%2F</url>
    <content type="text"><![CDATA[To initialize tuples, arrays, and other types of sequences, you could also start from a listcomp, but a genexpsaves memory because it yields items one by one using the iterator protocol instead of building a whole listjust to feed another constructor.12345678910&gt;&gt;&gt; symbols = '$¢£¥€¤'&gt;&gt;&gt; tuple(ord(symbol) for symbol in symbols)(36, 162, 163, 165, 8364, 164)#If the generator expression is the single argument in a function call, there is no need to duplicate the #enclosing parentheses.&gt;&gt;&gt; import array&gt;&gt;&gt; array.array('I', (ord(symbol) for symbol in symbols))array('I', [36, 162, 163, 165, 8364, 164])#The array constructor takes two arguments, so the parentheses around the generator expression are mandatory.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C02_listcomp_speed.py]]></title>
    <url>%2F2018%2F04%2F22%2FC02-listcomp-speed-py%2F</url>
    <content type="text"><![CDATA[Container sequences and Flat sequencesContainer sequences:list, tuple, and collections.deque can hold items of different types. Flat sequences:str, bytes, bytearray, memoryview, and array.array hold items of one type. Container sequences hold references to the objects they contain, which may be of any type, while flatsequences physically store the value of each item within its own memory space, and not as distinctobjects. Mutable sequences and Immutable sequencesMutable sequences:list, bytearray, array.array, collections.deque, and memoryview Immutable sequences:tuple, str, and bytes map and filter were faster than the equivalent listcomps123456789101112131415161718import timeitTIMES = 10000SETUP = """symbols = '$¢£¥€¤'def non_ascii(c): return c &gt; 127"""def clock(label, cmd): res = timeit.repeat(cmd, setup=SETUP, number=TIMES) print(label, *('&#123;:.3f&#125;'.format(x) for x in res))clock('listcomp :', '[ord(s) for s in symbols if ord(s) &gt; 127]')clock('listcomp + func :', '[ord(s) for s in symbols if non_ascii(ord(s))]')clock('filter + lambda :', 'list(filter(lambda c: c &gt; 127, map(ord, symbols)))')clock('filter + func :', 'list(filter(non_ascii, map(ord, symbols)))')]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C01_repr__,__str__,__bool__]]></title>
    <url>%2F2018%2F04%2F22%2FC01-repr-str-bool%2F</url>
    <content type="text"><![CDATA[repr, strThe repr special method is called by the repr built-in to get the string representation of the object forinspection.The interactive console and debugger call repr on the results of the expressions evaluated. Contrast repr with str, which is called by the str() constructor and implicitly used by the printfunction. str should return a string suitable for display to end users.If you only implement one ofthese special methods, choose repr, because when no custom str is available, Python will callrepr as a fallback. boolBy default, instances of user-defined classes are considered truthy, unless either__bool__ or lenis implemented. Basically, bool(x) calls x.bool() and uses the result. If bool is not implemented,Python tries to invoke x.len(), and if that returns zero, bool returns False. Otherwise bool returns True.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C01_How Special Methods Are Used]]></title>
    <url>%2F2018%2F04%2F22%2FC01-How-Special-Methods-Are-Used%2F</url>
    <content type="text"><![CDATA[First thing to know about special methods is that they are meant to be called by thePython interpreter,and not by you. You don’t write my_object.len(). You writelen(my_object) and, if my_object is an instance of a user-defined class, then Python calls the len instance method you implemented. Special method call is implicit. For example, the statement for i in x: actually causes the invocation of iter(x), which in turn may call x.iter() if that is available.Normally, your code should not have many direct calls to special methods. Unless you are doing a lotof metaprogramming, you should be implementing special methods more often than invoking themexplicitly. The only special method that is frequently called by user code directly is init, to invokethe initializer of the superclass in your own init implementation. If you need to invoke a special method, it is usually better to call the related built-in function (e.g., len,iter, str, etc). These built-ins call the corresponding special method, but often provide other services and—for built-in types—are faster than method calls.]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>fluent python</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C29_mysqldump]]></title>
    <url>%2F2018%2F04%2F22%2FC29-mysqldump%2F</url>
    <content type="text"><![CDATA[备份 使用命令行实用程序mysqldump 转储所有数据库内容到某个外部文件。在进行常规备份前这个实用程序应该正常运行，以便能正确地备份转储文件。 可用命令行实用程序mysqlhotcopy 从一个数据库复制所有数据（并非所有数据库引擎都支持这个实用程序）。 可以使用MySQL的BACKUP TABLE 或SELECT INTO OUTFILE 转储所有数据到某个外部文件。这两条语句都接受将要创建的系统文件名，此系统文件必须不存在，否则会出错。数据可以用RESTORE TABLE 来复原。 为了保证所有数据被写到磁盘（包括索引数据），可能需要在进行备份前使用FLUSH TABLES 语句。 维护ANALYZE TABLE ，用来检查表键是否正确1ANALYZE TABLE orders; CHECK TABLE 用来针对许多问题对表进行检查。在MyISAM 表上还对索引进行检查。CHECK TABLE 支持一系列的用于MyISAM 表的方式。CHANGED 检查自最后一次检查以来改动过的表。EXTENDED 执行最彻底的检查，FAST 只检查未正常关闭的表，MEDIUM 检查所有被删除的链接并进行键检验，QUICK 只进行快速扫描。 如果MyISAM 表访问产生不正确和不一致的结果，可能需要用REPAIR TABLE 来修复相应的表。这条语句不应该经常使用，如果需要经常使用，可能会有更大的问题要解决。 如果从一个表中删除大量数据，应该使用OPTIMIZE TABLE 来收回所用的空间，从而优化表的性能 启动问题 mysqld –safe-mode 装载减去某些最佳配置的服务器； –verbose 显示全文本消息（为获得更详细的帮助消息与–help 联合使用）； –version 显示版本信息然后退出。 日志MySQL维护管理员依赖的一系列日志文件。主要的日志文件有以下几种。 错误日志。它包含启动和关闭问题以及任意关键错误的细节。此日志通常名为hostname.err ，位于data 目录中。此日志名可用–log-error 命令行选项更改。 查询日志。它记录所有MySQL活动，在诊断问题时非常有用。此日志文件可能会很快地变得非常大，因此不应该长期使用它。此日志通常名为hostname.log ，位于data 目录中。此名字可以用–log 命令行选项更改。 二进制日志。它记录更新过数据（或者可能更新过数据）的所有语句。此日志通常名为hostname-bin ，位于data 目录内。此名字可以用–log-bin 命令行选项更改。注意，这个日志文件是MySQL 5中添加的，以前的MySQL版本中使用的是更新日志。 缓慢查询日志。顾名思义，此日志记录执行缓慢的任何查询。这个日志在确定数据库何处需要优化很有用。此日志通常名为hostname-slow.log ，位于data 目录中。此名字可以用–log-slow-queries 命令行选项更改。 在使用日志时，可用FLUSH LOGS 语句来刷新和重新开始所有日志文件。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C28_用户管理]]></title>
    <url>%2F2018%2F04%2F22%2FC28-%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[MySQL用户账号和信息存储在名为mysql 的MySQL数据库中。一般不需要直接访问mysql 数据库和表，但有时需要直接访问。需要直接访问它的时机之一是在需要获得所有用户账号列表时。12USE mysql;SELECT user FROM user; 创建用户账号一般来说CREATE USER 是最清楚和最简单的句子。此外，也可以通过直接插入行到user 表来增加用户，不过为安全起见，一般不建议这样做。MySQL用来存储用户账号信息的表（以及表模式等）极为重要，对它们的任何毁坏都可能严重地伤害到MySQL服务器。因此，相对于直接处理来说，最好是用标记和函数来处理这些表。123CREATE USER ben IDENTIFIED BY 'password';-- IDENTIFIED BY 指定的口令为纯文本，MySQL将在保存到user 表之前对其进行加密。为了作为散列值指-- 定口令，使用IDENTIFIED BY PASSWORD 。 RENAME USER1RENAME USER ben TO bforra; DROP USER1DROP USER bforra; 设置访问权限12SHOW GRANTS FOR bforra;--为看到赋予用户账号的权限 为设置权限，使用GRANT 语句。GRANT 要求你至少给出以下信息： 要授予的权限； 被授予访问权限的数据库或表； 用户名。每个GRANT 添加（或更新）用户的一个权限。MySQL读取所有授权，并根据它们确定权限。GRANT 的反操作为REVOKE 123456789GRANT SELECT ON crashcourse.* TO bforra;-- 此GRANT 允许用户在crashcourse.* （crashcourse 数据库的所有表）上使用SELECT 。通过只授予-- SELECT 访问权限，用户bforta 对crashcourse 数据库中的所有数据具有只读访问权限。GRANT SELECT, INSERT ON crashcourse.* TO beforta;-- 可通过列出各权限并用逗号分隔，将多条GRANT 语句串在一起REVOKE SELECT ON crashcourse.* FROM bfoora; -- 被撤销的访问权限必须存在,否则会报错。 GRANT 和REVOKE 可在几个层次上控制访问权限： 整个服务器，使用GRANT ALL 和REVOKE ALL ； 整个数据库，使用ON database.* ； 特定的表，使用ON database.table ； 特定的列； 特定的存储过程。###更改password新口令必须传递到Password() 函数进行加密。 1234SET PASSWORD FOR befora= PASSWORD('new password')SET PASSWORD = PASSWORD('new password')-- 设置自己的口令]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C27_CHARACTER SET, COLLATE]]></title>
    <url>%2F2018%2F04%2F22%2FC27-CHARACTER-SET-COLLATE%2F</url>
    <content type="text"><![CDATA[给表指定字符集和校对123456CREATE TABLE mytable( columnn1 INT, columnn2 VARCHAR(10)) DEFAULT CHARACTER SET hebrew COLLATE hebrew_general_ci; 如果指定CHARACTER SET 和COLLATE 两者，则使用这些值。 如果只指定CHARACTER SET ，则使用此字符集及其默认的校对（如SHOW CHARACTER SET 的结果中所示）。 如果既不指定CHARACTER SET ，也不指定COLLATE ，则使用数据库默认。 每个列设置1234567891011CREATE TABLE mytable( columnn1 INT, columnn2 VARCHAR(10), column3 VARCHAR(10) CHARACTER SET latin1 COLLATE latin1_general_ci) DEFAULT CHARACTER SET hebrew COLLATE hebrew_general_ci;SELECT * FROM customersORDER BY lastname, firstname COLLATE latin1_general_cs;-- 此SELECT 使用COLLATE 指定一个备用的校对顺序（在这个例子中，为区分大小写的校对）。这显然将-- 会影响到结果排序的次序。 COLLATE 还可以用于GROUP BY 、HAVING 、聚集函数、别名等。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C26_COMMIT ROLLBACK]]></title>
    <url>%2F2018%2F04%2F22%2FC26-COMMIT-ROLLBACK%2F</url>
    <content type="text"><![CDATA[MyISAM 和InnoDB 是两种最常使用的引擎。前者不支持明确的事务处理管理，而后者支持。 事务处理（transactionprocessing）可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。 事务（transaction） 指一组SQL语句； 回退（rollback） 指撤销指定SQL语句的过程； 提交（commit） 指将未存储的SQL语句结果写入数据库表； 保留点（savepoint） 指事务处理中设置的临时占位符（place-holder），你可以对它发布回退（与回退整个事务处理不同）。 标识事务的开始1START TRANSANCTION 使用ROLLBACKROLLBACK 只能在一个事务处理内使用（在执行一条START TRANSACTION 命令之后）。事务处理用来管理INSERT 、UPDATE 和DELETE 语句。你不能回退SELECT 语句。（这样做也没有什么意义。）你不能回退CREATE 或DROP 操作。事务处理块中可以使用这两条语句，但如果你执行回退，它们不会被撤销。123456789SELECT * FROM ordertotals;START TRANSACTION;DELETE FROM ordertotals;SELECT * FROM ordertotals;ROLLBACK;SELECT * FROM ordertotals-- 首先执行一条SELECT 以显示该表不为空。然后开始一个事务处理，用一条DELETE 语句删除ordertotals -- 中的所有行。另一条SELECT 语句验证ordertotals 确实为空。这时用一条ROLLBACK 语句回退START -- TRANSACTION 之后的所有语句，最后一条SELECT 语句显示该表不为空。 使用COMMIT一般的MySQL语句都是直接针对数据库表执行和编写的。这就是所谓的隐含提交（implicitcommit），即提交（写或保存）操作是自动进行的。 但是，在事务处理块中，提交不会隐含地进行。为进行明确的提交，使用COMMIT 语句。1234567-- 从系统中完全删除订单20010 。因为涉及更新两个数据库表orders 和orderItems ，所以使用事务处理-- 块来保证订单不被部分删除。最后的COMMIT 语句仅在不出错时写出更改。如果第一条DELETE 起作-- 用，但第二条失败，则DELETE 不会提交（实际上，它是被自动撤销的）。START TRANSACTION;DELETE FROM orderitems WHERE order_num = 20010;DELETE FROM orders WHERE order_num = 20010;COMMIT; 使用保留点简单的ROLLBACK 和COMMIT 语句就可以写入或撤销整个事务处理。但是，只是对简单的事务处理才能这样做，更复杂的事务处理可能需要部分提交或回退。 为了支持回退部分事务处理，必须能在事务处理块中合适的位置放置占位符。这样，如果需要回退，可以回退到某个占位符。123SAVEPOINT delete1;ROLLBACK TO delete1; 保留点在事务处理完成（执行一条ROLLBACK 或COMMIT ）后自动释放。自MySQL 5以来，也可以用RELEASE SAVEPOINT 明确地释放保留点。 更改默认的提交行为默认的MySQL行为是自动提交所有更改。换句话说，任何时候你执行一条MySQL语句，该语句实际上都是针对表执行的，而且所做的更改立即生效。为指示MySQL不自动提交更改:1SET autocommit = 0;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C25_TRIGGER]]></title>
    <url>%2F2018%2F04%2F22%2FC25-TRIGGER%2F</url>
    <content type="text"><![CDATA[触发器是MySQL响应以下任意语句而自动执行的一条MySQL语句（或位于BEGIN 和END 语句之间的一组语句）： DELETE； INSERT； UPDATE。 其他MySQL语句不支持触发器。只有表才支持触发器，视图不支持（临时表也不支持）。每个表每个事件每次只允许一个触发器。因此，每个表最多支持6个触发器（每条INSERT 、UPDATE 和DELETE 的之前和之后）。单一触发器不能与多个事件或多个表关联，所以，如果你需要一个对INSERT 和UPDATE 操作执行的触发器，则应该定义两个触发器。 触发器名必须在每个表中唯一，但不是在每个数据库中唯一。这表示同一数据库中的两个表可具有相同名字的触发器。这在其他每个数据库触发器名必须唯一的DBMS中是不允许的，最好是在数据库范围内使用唯一的触发器名。 如果BEFORE 触发器失败，则MySQL将不执行请求的操作。此外，如果BEFORE 触发器或语句本身失败，MySQL将不执行AFTER 触发器（如果有的话）。 在创建触发器时，需要给出4条信息： 唯一的触发器名； 触发器关联的表； 触发器应该响应的活动（DELETE 、INSERT 或UPDATE ）； 触发器何时执行（处理之前或之后）。 12345#对每个成功的插入，显示Product added 消息。CREATE TRIGGER newproduct AFTER INSERT ON productsFOR EACH ROW SELECT 'Product added';#删除触发器DROP TRIGGER newproduct; INSERT触发器 INSERT 触发器在INSERT 语句执行之前或之后执行。需要知道以下几点： 在INSERT 触发器代码内，可引用一个名为NEW 的虚拟表，访问被插入的行； 在BEFORE INSERT 触发器中，NEW 中的值也可以被更新（允许更改被插入的值）； 对于AUTO_INCREMENT 列，NEW 在INSERT 执行之前包含0 ，在INSERT 执行之后包含新的自动生成值。12345#MySQL生成一个新订单号并保存到order_num 中。触发器从NEW.order_num 取得这个值并返回它。此#触发器必须按照AFTER INSERT 执行，因为在BEFORE INSERT 语句执行之前，新order_num 还没有生成。#对于orders 的每次插入使用这个触发器将总是返回新的订单号。CREATE TRIGGER neworder AFTER INSERT ON ordersFOR EACH ROW SELECT NEW.order_num; DELETE触发器 DELETE 触发器在DELETE 语句执行之前或之后执行。需要知道以下两点： 在DELETE 触发器代码内，你可以引用一个名为OLD 的虚拟表，访问被删除的行； OLD 中的值全都是只读的，不能更新。123456CREATE TRIGGER deleteorder BEFORE DELETE ON ordersFOR EACH ROWBEGIN #使用BEGIN END 块的好处是触发器能容纳多条SQL语句 INSERT INTO archive_orders(order_num, order_date, cust_id) VALUES(OLD.order_num, OLD.order_date, OLD.cust_id);END; UPDATE触发器 UPDATE 触发器在UPDATE 语句执行之前或之后执行。需要知道以下几点： 在UPDATE 触发器代码中，你可以引用一个名为OLD 的虚拟表访问以前（UPDATE 语句前）的值，引用一个名为NEW 的虚拟表访问新更新的值； 在BEFORE UPDATE 触发器中，NEW 中的值可能也被更新（允许更改将要用于UPDATE 语句中的值）； OLD 中的值全都是只读的，不能更新。 12CREATE TRIGGER updatevendor BEFORE UPDATE ON vendorsFOR EACH ROW SET NEW.vend_state = Upper(NEW.vend_state); 与其他DBMS相比，MySQL5中支持的触发器相当初级。未来的MySQL版本中有一些改进和增强触发器支持的计划。 创建触发器可能需要特殊的安全访问权限，但是，触发器的执行是自动的。如果INSERT 、UPDATE 或DELETE 语句能够执行，则相关的触发器也能执行。 应该用触发器来保证数据的一致性（大小写、格式等）。在触发器中执行这种类型的处理的优点是它总是进行这种处理，而且是透明地进行，与客户机应用无关。 触发器的一种非常有意义的使用是创建审计跟踪。使用触发器，把更改（如果需要，甚至还有之前和之后的状态）记录到另一个表非常容易。 遗憾的是，MySQL触发器中不支持CALL 语句。这表示不能从触发器内调用存储过程。所需的存储过程代码需要复制到触发器内。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C29__getitem__, __setitem__]]></title>
    <url>%2F2018%2F04%2F22%2FC29-getitem-setitem%2F</url>
    <content type="text"><![CDATA[Indexing and SlicingIf defined in a class (or inherited by it), the getitem method is called automatically for instance-indexingoperations. When an instance X appears in an indexing expression like X[i], Python calls the getitemmethod inherited by the instance, passing X to the first argument and the index in brackets to the secondargument.123456789101112&gt;&gt;&gt; class Indexer:... def __getitem__(self, index):... return index ** 2...&gt;&gt;&gt; X = Indexer()&gt;&gt;&gt; X[2] # X[i] calls X.__getitem__(i)4&gt;&gt;&gt; for i in range(5):... print(X[i], end=' ') # Runs __getitem__(X, i) each time...0 1 4 9 16 slicingIn addition to indexing, getitem is also called for slice expressions. Slicing bounds are bundled up intoa slice object and passed to the list’s implementation of indexing. In fact, you can always pass a sliceobject manually—slice syntax is mostly syntactic sugar for indexing with a slice object.1234567891011121314151617181920212223242526272829&gt;&gt;&gt; L = [5, 6, 7, 8, 9]&gt;&gt;&gt; L[slice(2, 4)] # Slice with slice objects[7, 8]&gt;&gt;&gt; L[slice(1, None)][6, 7, 8, 9]&gt;&gt;&gt; L[slice(None, −1)][5, 6, 7, 8]&gt;&gt;&gt; L[slice(None, None, 2)][5, 7, 9]&gt;&gt;&gt; class Indexer:... data = [5, 6, 7, 8, 9]... def __getitem__(self, index): # Called for index or slice... print('getitem:', index)... return self.data[index] # Perform index or slice...&gt;&gt;&gt; X = Indexer()&gt;&gt;&gt; X[0] # Indexing sends __getitem__ an integergetitem: 05&gt;&gt;&gt; X[2:4] # Slicing sends __getitem__ a slice objectgetitem: slice(2, 4, None)[7, 8]&gt;&gt;&gt; X[1:]getitem: slice(1, None, None)[6, 7, 8, 9]&gt;&gt;&gt; X[:-1]getitem: slice(None, −1, None)[5, 6, 7, 8] Index IterationThe for statement works by repeatedly indexing a sequence from zero to higher indexes, until an out-of-bounds exception is detected. Because of that, getitem also turns out to be one way to overloaditeration in Python—if this method is defined, for loops call the class’s getitem each time through,with successively higher offsets.12345678910111213&gt;&gt;&gt; class stepper:... def __getitem__(self, i):... return self.data[i]...&gt;&gt;&gt; X = stepper() # X is a stepper object&gt;&gt;&gt; X.data = 'Spam'&gt;&gt;&gt;&gt;&gt;&gt; X[1] # Indexing calls __getitem__'p'&gt;&gt;&gt; for item in X: # for loops call __getitem__... print(item, end=' ') # for indexes items 0..N...S p a m Any class that supports for loops automatically supports all iteration contexts in Python. For example, thein membership test, list comprehensions, the map built-in, list and tuple assignments, and typeconstructors will also call getitem automatically, if it’s defined.123456789101112131415161718&gt;&gt;&gt; 'p' in X # All call __getitem__ tooTrue&gt;&gt;&gt; [c for c in X] # List comprehension['S', 'p', 'a', 'm']&gt;&gt;&gt; list(map(str.upper, X)) # map calls (use list() in 3.0)['S', 'P', 'A', 'M']&gt;&gt;&gt; (a, b, c, d) = X # Sequence assignments&gt;&gt;&gt; a, c, d('S', 'a', 'm')&gt;&gt;&gt; list(X), tuple(X), ''.join(X)(['S', 'p', 'a', 'm'], ('S', 'p', 'a', 'm'), 'Spam')&gt;&gt;&gt; X&lt;__main__.stepper object at 0x00A8D5D0&gt;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>learning python 5th</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C01_named tuple, random.choice]]></title>
    <url>%2F2018%2F04%2F14%2FC01-named-tuple-random-choice%2F</url>
    <content type="text"><![CDATA[namedtuplePython中的tuples（元组）是经常用来表示简单的数据结构，但它只能通过下标来访问其中的数据，这导致代码难于阅读和维护。Python的collections模块包含一个namedtuple()函数，用来创建一个tuple的子类，其可以通过属性名称访问tuple中的元素。1234567891011121314&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; NetworkAddress = namedtuple('NetworkAddress',['hostname','port'])&gt;&gt;&gt; a = NetworkAddress('www.python.org',80)&gt;&gt;&gt; a.hostname'www.python.org'&gt;&gt;&gt; a.port80&gt;&gt;&gt; host, port = a&gt;&gt;&gt; len(a)2&gt;&gt;&gt; type(a)&lt;class '__main__.NetworkAddress'&gt;&gt;&gt;&gt; isinstance(a, tuple)True 支持所有普通tuple的操作，而且增加了通过使用属性名访问其中数据的功能。但使用namedtuple访问属性值时，不如通过类那样高效。 1234567class Stock(object): def __init__(self,name,shares,price): self.name = name self.shares = shares self.price = price#可定义为Stock=namedtuple('Stock',['name', 'shares', 'price']) 作为字典的替代，因为字典存储需要更多的内存空间。 如果你需要构建一个非常大的包含字典的数据结构，那么使用命名元组会更加高效。 但是需要注意的是，不像字典那样，一个命名元组是不可更改的。 需要改变属性的值，可以使用命名元组实例的 _replace() 方法 123456789101112&gt;&gt;&gt; s = Stock('ACME', 100, 123.45)&gt;&gt;&gt; sStock(name='ACME', shares=100, price=123.45)&gt;&gt;&gt; s.shares = 75Traceback (most recent call last):File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: can't set attributes._replace(shares=75)&gt;&gt;&gt; sStock(name='ACME', shares=75, price=123.45)&gt;&gt;&gt; randomrandom.choice从一个序列中随机的抽取一个元素123456&gt;&gt;&gt; import random&gt;&gt;&gt; values = [1, 2, 3, 4, 5, 6]&gt;&gt;&gt; random.choice(values)2&gt;&gt;&gt; random.choice(values)3 random.sample提取出N个不同元素的样本123456&gt;&gt;&gt; random.sample(values,4)[4, 5, 2, 1]&gt;&gt;&gt; random.sample(values,3)[4, 1, 2]&gt;&gt;&gt; random.sample(values,3)[5, 4, 2] random.shuffle123456&gt;&gt;&gt; random.shuffle(values)&gt;&gt;&gt; values[4, 3, 5, 1, 2]&gt;&gt;&gt; random.shuffle(values)&gt;&gt;&gt; values[4, 5, 2, 3, 1] random.randint生成随机整数123456&gt;&gt;&gt; random.randint(0,10)6&gt;&gt;&gt; random.randint(0,10)0&gt;&gt;&gt; random.randint(0,10)10 random.random()生成0到1范围内均匀分布的浮点数 random.getrandbits()获取N位随机位(二进制)的整数12&gt;&gt;&gt; random.getrandbits(22)343509 random.seed()random 模块使用 Mersenne Twister 算法来计算生成随机数。这是一个确定性算法， 但是你可以通过random.seed() 函数修改初始化种子123random.seed() # Seed based on system time or os.urandom()random.seed(12345) # Seed based on integer givenrandom.seed(b'bytedata') # Seed based on byte data]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>learning python 5th</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C24_CURSOR]]></title>
    <url>%2F2018%2F04%2F14%2FC24-CURSOR%2F</url>
    <content type="text"><![CDATA[需要在检索出来的行中前进或后退一行或多行。这就是使用游标的原因。游标（cursor）是一个存储在MySQL服务器上的数据库查询，它不是一条SELECT 语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。 MySQL游标只能用于存储过程（和函数）。使用游标涉及几个明确的步骤: 在能够使用游标前，必须声明（定义）它。这个过程实际上没有检索数据，它只是定义要使用的SELECT 语句。 一旦声明后，必须打开游标以供使用。这个过程用前面定义的SELECT 语句把数据实际检索出来。 对于填有数据的游标，根据需要取出（检索）各行。 在结束游标使用时，必须关闭游标。 DECLARE CURSOR12345678#这个存储过程处理完成后，游标就消失（因为它局限于存储过程）。CREATE PROCEDURE processorders()BEGIN DECLARE ordernumbers CURSOR # DECLARE 语句用来定义和命名游标 FOR SELECT ordernum FROM orders;END; 打开和关闭游标CLOSE 释放游标使用的所有内部内存和资源，因此在每个游标不再需要时都应该关闭。1234567891011121314CREATE PROCEDURE processorders()BEGIN -- Declare the cursor DECLARE ordernumbers CURSOR FOR SELECT order_num FROM orders; -- Open the cursor OPEN ordernumbers; -- Close the cursor CLOSE ordernumbers;END; FETCH游标数据在一个游标被打开后，可以使用FETCH 语句分别访问它的每一行。FETCH 指定检索什么数据（所需的列），检索出来的数据存储在什么地方。它还向前移动游标中的内部行指针，使下一条FETCH 语句检索下一行（不重复读取同一行）。 123456789101112131415161718192021222324252627282930313233CREATE PROCEDURE processorders()BEGIN -- Declare local variables DECLARE done BOOLEAN DEFAULT 0; DECLARE o INT; -- Declare the cursor DECLARE ordernumbers CURSOR FOR SELECT order_num FROM orders; -- Declare continue handler -- 当SQLSTATE '02000' 出现时，SET done=1 。SQLSTATE '02000' 是一个未找到条件，当REPEAT 由于 -- 没有更多的行供循环而不能继续时，出现这个条件。 --- 句柄必须在游标之后定义 DECLARE CONTINUE HANDLER FOR SQLSTATE '02000' SET done=1; -- Open the cursor OPEN ordernumbers; -- Loop through all rows REPEAT -- Get order number FETCH ordernumbers INTO o; -- End of loop UNTIL done END REPEAT; -- Close the cursor CLOSE ordernumbers;END 下面例子中，我们增加了另一个名为t 的变量（存储每个订单的合计）。此存储过程还在运行中创建了一个新表（如果它不存在的话），名为ordertotals 。这个表将保存存储过程生成的结果。FETCH 像以前一样取每个order_num ，然后用CALL 执行另一个存储过程（我们在前一章中创建）来计算每个订单的带税的合计（结果存储到t ）。最后，用INSERT 保存每个订单的订单号和合计。123456789101112131415161718192021222324252627282930313233343536373839404142CREATE PROCEDURE processorders()BEGIN -- Declare local variables DECLARE done BOOLEAN DEFAULT 0; DECLARE o INT; DECLARE t DECIMAL(8,2); -- Declare the cursor DECLARE ordernumbers CURSOR FOR SELECT order_num FROM orders; -- Declare continue handler DECLARE CONTINUE HANDLER FOR SQLSTATE '02000' SET done=1; -- Create a table to store the results CREATE TABLE IF NOT EXISTS ordertotals (order_num INT, total DECIMAL(8,2)); -- Open the cursor OPEN ordernumbers; -- Loop through all rows REPEAT -- Get order number FETCH ordernumbers INTO o; -- Get the total for this order CALL ordertotal(o, 1, t); -- Insert order and total into ordertotals INSERT INTO ordertotals(order_num, total) VALUES(o, t); -- End of loop UNTIL done END REPEAT; -- Close the cursor CLOSE ordernumbers;END;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C23_存储过程]]></title>
    <url>%2F2018%2F04%2F14%2FC23-%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[MySQL称存储过程的执行为调用，因此MySQL执行存储过程的语句为CALL 。CALL 接受存储过程的名字以及需要传递给它的任意参数。1234CALL productpricing ( @pricelow, @pricehigh, @priceaverage);#执行名为productpricing 的存储过程，它计算并返回产品的最低、最高和平均价格 CREATR PROCEDURE 创建存储过程1234567CREATE PROCEDURE productpricing()BEGIN SELECT Avg(prod_price) AS priceaverage FROM products;END;#此存储过程名为productpricing ，用CREATE PROCEDURE productpricing() 语句定义。如果存储过程接受#参数，它们将在() 中列举出来。 更改命令行分隔符DELIMITER// 告诉命令行实用程序使用// 作为新的语句结束分隔符1234567DELIMITER // CREATE PROCEDURE productpricing() BEGIN SELECT Avg(prod_price) AS priceaverage FROM products; END // 删除存储过程1234DROP PROCEDURE productpricing;DROP PROCEDURE productpricing IF EXISTS;# 使用参数关键字OUT 指出相应的参数用来从存储过程传出一个值（返回给调用者）。MySQL支持IN （传递给存储过程）、OUT （从存储过程传出，如这里所用）和INOUT （对存储过程传入和传出）类型的参数。存储过程的代码位于BEGIN 和END 语句内，一系列SELECT 语句，用来检索值，然后保存到相应的变量（通过指定INTO 关键字）。 所有MySQL变量都必须以@ 开始。 OUT 参数123456789101112131415161718192021222324252627CREATE PROCEDURE productpricing( OUT pl DECIMAL(8,2), OUT ph DECIMAL(8,2), OUT pa DECIMAL(8,2))BEGIN SELECT Min(prod_price) INTO pl FROM products; SELECT Max(prod_price) INTO ph FROM products; SELECT Avg(prod_price) INTO pa FROM products;END;#调用productpricing， 指定三个变量,#在调用时，这条语句并不显示任何数据。它返回以后可以显示（或在其他处理中使用）的变量。CALL productpricing(@pricelow,@pricehigh,@priceaverage);#显示检索出的产品平均价格，可如下进行：SELECT @pricehigh, @pricelow, @priceaverage; IN, OUT 参数12345678910111213CREATE PROCEDURE ordertotal(IN onumber INT,OUT ototal DECIMAL(8,2))BEGINSELECT Sum(item_price * quantity)FROM orderitemsWHERE order_num = onumberINTO ototal;END;#调用ordertotal, 第一个参数为订单号，第二个参数为包含计算出来的合计的变量名CALL ordertotal(20005, @total); 建立智能存储过程`sql #注释 – – Name: ordertotal– Parameters: onumber = order number– taxable = 0 if not taxable, 1 if taxable– ototal = order total variable CREATE PROCEDURE ordertotal( IN onumber INT, IN taxable BOOLEAN, OUT ototal DECIMAL(8,2)) COMMENT ‘Obtain order total, optionally adding tax’ #将在SHOW PROCEDURE STATUS 的结果中显示 BEGIN # DECLARE 语句定义了两个局部变量 DECLARE total DECIMAL(8,2); DECLARE taxrate INT DEFAULT 6; SELECT Sum(item_price * quantity) FROM orderitems WHERE order_num = onumber INTO total; IF taxable THEN SELECT total + (total/100*taxrate) INTO total; END IF; SELECT total INTO ototal; END; CALL ordertotal(20005, 1, @total); 获得包括何时、由谁创建等详细信息的存储过程列表，使用SHOW PROCEDURE STATUS#使用LIKE 指定一个过滤模式SHOW PROCEDURE STATUS LIKE ‘ordertotal’;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C22_View]]></title>
    <url>%2F2018%2F04%2F14%2FC22-View%2F</url>
    <content type="text"><![CDATA[视图是虚拟的表。与包含数据的表不一样，视图只包含使用时动态检索数据的查询 在视图创建之后，可以用与表基本相同的方式利用它们。可以对视图执行SELECT 操作，过滤和排序数据，将视图联结到其他视图或表，甚至能添加和更新数据。 重要的是知道视图仅仅是用来查看存储在别处的数据的一种设施。视图本身不包含数据，因此它们返回的数据是从其他表中检索出来的。在添加或更改这些表中的数据时，视图将返回改变过的数据。视图的一些常见应用: 重用SQL语句。 简化复杂的SQL操作。在编写查询后，可以方便地重用它而不必知道它的基本查询细节。 使用表的组成部分而不是整个表。 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限。 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。 视图的规则和限制: 与表一样，视图必须唯一命名（不能给视图取与别的视图或表相同的名字）。 对于可以创建的视图数目没有限制。 为了创建视图，必须具有足够的访问权限。这些限制通常由数据库管理人员授予。 视图可以嵌套，即可以利用从其他视图中检索数据的查询来构造一个视图。 ORDER BY 可以用在视图中，但如果从该视图检索数据SELECT 中也含有ORDER BY ，那么该视图中的 ORDER BY 将被覆盖。 视图不能索引，也不能有关联的触发器或默认值。 视图可以和表一起使用。例如，编写一条联结表和视图的SELECT 语句。 CREATE VIEW1234567891011121314151617181920212223242526CREATE VIEW productcustomers ASSELECT cust_name, cust_contact, prod_idFROM customers, orders, orderitemsWHERE customers.cust_id = orders.cust_id AND orderitems.order_num = orders.order_num;CREATE VIEW vendorlocations ASSELECT Concat(RTrim(vend_name), ' (', RTrim(vend_country), ')') AS vend_titleFROM vendorsORDER BY vend_name;#过滤CREATE VIEW customeremaillist ASSELECT cust_id, cust_name, cust_emailFROM customersWHERE cust_email IS NOT NULL;# 计算字段CREATE VIEW orderitemsexpanded ASSELECT order_num, prod_id, quantity, item_price, quantity*item_price AS expanded_priceFROM orderitems; 更新视图视图是可更新的（即，可以对它们使用INSERT 、UPDATE 和DELETE ）。更新一个视图将更新其基表（视图本身没有数据）。如果你对视图增加或删除行，实际上是对其基表增加或删除行。 并非所有视图都是可更新的。基本上可以说，如果MySQL不能正确地确定被更新的基数据，则不允许更新（包括插入和删除）。这实际上意味着，如果视图定义中有以下操作，则不能进行视图的更新： 分组（使用GROUP BY 和HAVING ）； 联结； 子查询； 并； 聚集函数（Min() 、Count() 、Sum() 等）； DISTINCT ； 导出（计算）列 一般，应该将视图用于检索（SELECT 语句）而不用于更新（INSERT 、UPDATE 和DELETE ）。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C21_ALTER TABLE]]></title>
    <url>%2F2018%2F04%2F14%2FC21-ALTER-TABLE%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223#给表添加一个列ALTER TABLE vendorsADD vend_phone CHAR(20);#删除一个列ALTER TABLE VendorsDROP COLUMN vend_phone;#定义外键ALTER TABLE orderitemsADD CONSTRAINT fk_orderitems_ordersFOREIGN KEY (order_num) REFERENCES orders (order_num);ALTER TABLE orderitemsADD CONSTRAINT fk_orderitems_products FOREIGN KEY (prod_id)REFERENCES products (prod_id);ALTER TABLE ordersADD CONSTRAINT fk_orders_customers FOREIGN KEY (cust_id)REFERENCES customers (cust_id);ALTER TABLE productsADD CONSTRAINT fk_products_vendorsFOREIGN KEY (vend_id) REFERENCES vendors (vend_id); 复杂的表结构更改一般需要手动删除过程，它涉及以下步骤： 用新的列布局创建一个新表； 使用INSERT SELECT 语句（关于这条语句的详细介绍，请参阅第19章）从旧表复制数据到新表。如果有必要，可使用转换函数和计算字段； 检验包含所需数据的新表； 重命名旧表（如果确定，可以删除它）； 用旧表原来的名字重命名新表； 根据需要，重新创建触发器、存储过程、索引和外键。 DROP TABLE12#删除表没有确认，也不能撤销DROP TABLE customers2; RENAME TABLE123RENAME TABLE backup_customers TO customers, backup_vendors TO vendors, backup_products TO products;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C21_CREATE TABLE]]></title>
    <url>%2F2018%2F04%2F14%2FC21-CREATE-TABLE%2F</url>
    <content type="text"><![CDATA[PRIMARY KEY如果主键使用单个列，则它的值必须唯一。如果使用多个列，则这些列的组合值必须唯一。 123456789101112PRIMARY KEY (vend_id) #用单个列作为主键#创建由多个列组成的主键,应该以逗号分隔的列表给出各列名CREATE TABLE orderitems( order_num int NOT NULL , order_item int NOT NULL , prod_id char(10) NOT NULL , quantity int NOT NULL , item_price decimal(8,2) NOT NULL , PRIMARY KEY (order_num, order_item)) ENGINE=InnoDB; AUTO_INCREMENT每个表只允许一个AUTO_INCREMENT 列，而且它必须被索引（如，通过使它成为主键）。1234567cust_id int NOT NULL AUTO_INCREMENT,#AUTO_INCREMENT 告诉MySQL，本列每当增加一行时自动增量。每次执行一个INSERT 操作时，MySQL#自动对该列增量，给该列赋予下一个可用的值。这样给每个行分配一个唯一的cust_id ，从而可以用作主#键值。SELECT last_insert_id();#返回最后一个AUTO_INCREMENT 值 DEFAULT如果在插入行时没有给出值，MySQL允许指定此时使用的默认值。默认值用CREATE TABLE 语句的列定义中的DEFAULT关键字指定。 1quantity int NOT NULL DEFAULT 1, ENGINE引擎类型可以混用。混用引擎类型有一个大缺陷。外键（用于强制实施引用完整性）不能跨引擎，即使用一个引擎的表不能引用具有使用不同引擎的表的外键。 InnoDB 是一个可靠的事务处理引擎，它不支持全文本搜索； MEMORY 在功能等同于MyISAM ，但由于数据存储在内存中，速度很快（特别适合于临时 表 MyISAM 是一个性能极高的引擎，它支持全文本搜索，但不支持事务处理。 sqlCREATE TABLE orderitems( order_num int NOT NULL , order_item int NOT NULL , prod_id char(10) NOT NULL , quantity int NOT NULL DEFAULT 1, item_price decimal(8,2) NOT NULL , PRIMARY KEY (order_num, order_item)) ENGINE=InnoDB;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C20_UPDATE_DELETE]]></title>
    <url>%2F2018%2F04%2F14%2FC20-UPDATE-DELETE%2F</url>
    <content type="text"><![CDATA[12345678UPDATE customersSET cust_email = 'elmer@fudd.com', cust_name = 'The Fudds',WHERE cust_id = 10005;UPDATE customersSET cust_email = NULL #NULL 用来去除cust_email 列中的值。WHERE cust_id = 10005; IGNORE如果用UPDATE 语句更新多行，并且在更新这些行中的一行或多行时出一个现错误，则整个UPDATE 操作被取消（错误发生前更新的所有行被恢复到它们原来的值）。为即使是发生错误，也继续进行更新，可使用IGNORE 关键字 1UPDATE IGNORE customers ... DELETE12DELETE FROM customersWHERE cust_id = 10006; Attention 除非确实打算更新和删除每一行，否则绝对不要使用不带WHERE 子句的UPDATE 或DELETE 语句。 保证每个表都有主键（如果忘记这个内容，请参阅第15章），尽可能像WHERE 子句那样使用它（可以指 定各主键、多个值或值的范围）。 在对UPDATE 或DELETE 语句使用WHERE 子句前，应该先用SELECT 进行测试，保证它过滤的是正确的记 录，以防编写的WHERE 子句不正确。 使用强制实施引用完整性的数据库（关于这个内容，请参阅第15章），这样MySQL将不允许删除具有与 其他表相关联的数据的行。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C19_INSERT]]></title>
    <url>%2F2018%2F04%2F14%2FC19-INSERT%2F</url>
    <content type="text"><![CDATA[INSERT 是用来插入（或添加）行到数据库表的。插入可以用几种方式使用： 插入完整的行； 插入行的一部分； 插入多行； 插入某些查询的结果。 12345678910111213141516INSERT INTO CustomersVALUES(NULL, 'Pep E. LaPew', '100 Main Street', 'Los Angeles', 'CA', '90046', 'USA', NULL, NULL);#插入一个新客户到customers 表。存储到每个表列中的数据在VALUES 子句中给出，对每个列必须提供一#个值。如果某个列没有值（如上面的cust_contact 和cust_email 列），应该使用NULL 值（假定表允许对#该列指定空值）。各个列必须以它们在表定义中出现的次序填充。第一列cust_id 也为NULL 。这是因为#每次插入一个新行时，该列由MySQL自动增量。你不想给出一个值（这是MySQL的工作），又不能省略#此列（如前所述，必须给出每个列），所以指定一个NULL 值（它被MySQL忽略，MySQL在这里插入下#一个可用的cust_id 值）。 12345678910111213141516171819202122INSERT INTO customers(cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country, cust_contact, cust_email)VALUES('Pep E. LaPew', '100 Main Street', 'Los Angeles', 'CA', '90046', 'USA', NULL, NULL);#在插入行时，MySQL将用VALUES 列表中的相应值填入列表中的对应项。VALUES 中的第一个值对应于第#一个指定的列名。第二个值对应于第二个列名，如此等等。#因为提供了列名，VALUES 必须以其指定的次序匹配指定的列名，不一定按各个列出现在实际表中的次#序。其优点是，即使表的结构改变，此INSERT 语句仍然能正确工作。你会发现cust_id 的NULL 值是不必#要的，cust_id 列并没有出现在列表中，所以不需要任何值。 如果数据检索是最重要的（通常是这样），则你可以通过在INSERT 和INTO 之间添加关键字LOW_PRIORITY ，指示MySQL降低INSERT 语句的优先级, 也适用于UPDATE 和DELETE 语句1INSERT LOW_PRIORITY INTO insert 多条12345678910111213141516171819202122INSERT INTO customers(cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country)VALUES( 'Pep E. LaPew', '100 Main Street', 'Los Angeles', 'CA', '90046', 'USA' ), ( 'M. Martian', '42 Galaxy Way', 'New York', 'NY', '11213', 'USA' ); INSERT SELECT12345678910111213141516171819INSERT INTO customers(cust_id, cust_contact, cust_email, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_country)SELECT cust_id, cust_contact, cust_email, cust_name, cust_address, cust_city, cust_state, cust_zip, cust_countryFROM custnew; 这个例子使用INSERT SELECT 从custnew 中将所有数据导入customers 。SELECT 语句从custnew 检索出要插入的值，而不是列出它们。SELECT 中列出的每个列对应于customers 表名后所跟的列表中的每个列。这条语句将插入多少行有赖于custnew 表中有多少行。 为简单起见，这个例子在INSERT 和SELECT 语句中使用了相同的列名。但是，不一定要求列名匹配。事实上，MySQL甚至不关心SELECT 返回的列名。它使用的是列的位置，因此SELECT 中的第一列（不管其列名）将用来填充表列中指定的第一个列，第二列将用来填充表列中指定的第二个列，如此等等。这对于从使用不同列名的表中导入数据是非常有用的。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C18_布尔方式 搜索_boolean mode]]></title>
    <url>%2F2018%2F04%2F14%2FC18-%E5%B8%83%E5%B0%94%E6%96%B9%E5%BC%8F-%E6%90%9C%E7%B4%A2-boolean-mode%2F</url>
    <content type="text"><![CDATA[###MySQL支持全文本搜索的另外一种形式，称为布尔方式 （boolean mode）。以布尔方式，可以提供关于如下内容的细节： 要匹配的词； 要排斥的词（如果某行包含这个词，则不返回该行，即使它包含其他指定的词也是如此）； 排列提示（指定某些词比其他词更重要，更重要的词等级 表达式分组； 另外一些内容。 即使没有定义FULLTEXT 索引，也可以使用它。但这是一种非常缓慢的操作 12345SELECT note_textFROM productnotesWHERE Match(note_text) Against('heavy-rope*' IN BOOLEAN MODE);#匹配包含heavy 但不包含任意以rope 开始的词的行, -rope* 明确地指示MySQL排除包含rope* （任何以#rope 开始的词，包括ropes ）的行 + 包含，词必须存在 - 排除，词必须不出现 > 包含，而且增加等级值 &lt; 包含，且减少等级值 () 把词组成子表达式（允许这些子表达式作为一个组被包含、排除、排列等） ~ 取消一个词的排序值 * 词尾的通配符 ‘ ‘ 定义一个短语（与单个词的列表不一样，它匹配整个短语以便包含或排除这个短语） 1234SELECT note_textFROM productnotesWHERE Match(note_text) Against('+rabbit +bait'' IN BOOLEAN MODE);# 搜索匹配包含词rabbit 和bait 的行 1234SELECT note_textFROM productnotesWHERE Match(note_text) Against('rabbit bait' IN BOOLEAN MODE);#没有指定操作符，这个搜索匹配包含rabbit 和bait 中的至少一个词的行 1234SELECT note_textFROM productnotesWHERE Match(note_text) Against(''rabbit bait'' IN BOOLEAN MODE);#搜索匹配短语rabbit bait 而不是匹配两个词rabbit 和bait 1234SELECT note_textFROM productnotesWHERE Match(note_text) Against('&gt;rabbit &lt;carrot' IN BOOLEAN MODE);#匹配rabbit 和carrot ，增加前者的等级，降低后者的等级 12345SELECT note_textFROM productnotesWHERE Match(note_text) Against('+safe +(&lt;combination)' IN BOOLEANMODE);#搜索匹配词safe 和combination ，降低后者的等级]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C18_全文本搜索]]></title>
    <url>%2F2018%2F04%2F14%2FC18-%E5%85%A8%E6%96%87%E6%9C%AC%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[启用一般在创建表时启用全文本搜索。CREATE TABLE 语句接受FULLTEXT 子句，它给出被索引列的一个逗号分隔的列表。123456789CREATE TABLE productnotes( note_id int NOT NULL AUTO_INCREMENT, prod_id char(10) NOT NULL, note_date datetime NOT NULL, note_text text NULL , PRIMARY KEY(note_id), FULLTEXT(note_text)) ENGINE=MyISAM; 为了进行全文本搜索，MySQL根据子句FULLTEXT(note_text) 的指示对它进行索引。这里的FULLTEXT 索引单个列，如果需要也可以指定多个列。在定义之后，MySQL自动维护该索引。在增加、更新或删除行时，索引随之自动更新。 Match(), Against()在索引之后，使用两个函数Match() 和Against() 执行全文本搜索，其中Match() 指定被搜索的列，Against() 指定要使用的搜索表达式 Match(note_text) 指示MySQL针对指定的列进行搜索，Against(‘rabbit’) 指定词rabbit 作为搜索文本。由于有两行包含词rabbit ，这两个行被返回。123ELECT note_textFROM productnotesWHERE Match(note_text) Against('rabbit');]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C16_组合查询]]></title>
    <url>%2F2018%2F04%2F14%2FC16-%E7%BB%84%E5%90%88%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[多数SQL查询都只包含从一个或多个表中返回数据的单条SELECT 语句。MySQL也允许执行多个查询（多条SELECT 语句），并将结果作为单个查询结果集返回。这些组合查询通常称为并（union）或复合查询（compoundquery） UNION可用UNION 操作符来组合数条SQL查询。利用UNION ，可给出多条SELECT 语句，将它们的结果组合成单个结果集。 UNION 必须由两条或两条以上的SELECT 语句组成，语句之间用关键字UNION 分隔（因此，如果组合4条SELECT 语句，将要使用3个UNION 关键字）。 UNION 中的每个查询必须包含相同的列、表达式或聚集函数（不过各个列不需要以相同的次序列出）。 列数据类型必须兼容：类型不必完全相同，但必须是DBMS可以隐含地转换的类型（例如，不同的数值类型或不同的日期类型）。 123456789101112SELECT vend_id, prod_id, prod_priceFROM productsWHERE prod_price &lt;= 5UNIONSELECT vend_id, prod_id, prod_priceFROM productsWHERE vend_id IN (1001,1002);SELECT vend_id, prod_id, prod_priceFROM productsWHERE prod_price &lt;= 5 OR vend_id IN (1001,1002); 包含或取消重复的行UNION 从查询结果集中自动去除了重复的行, 这是UNION 的默认行为，但是如果需要，可以改变它。事实上，如果想返回所有匹配行，可使用UNION ALL 而不是UNION 。如果确实需要每个条件的匹配行全部出现（包括重复行），则必须使用UNION ALL 而不是WHERE 。 排序SELECT 语句的输出用ORDER BY 子句排序。在用UNION 组合查询时，只能使用一条ORDER BY 子句，它必须出现在最后一条SELECT 语句之后。对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分的情况，因此不允许使用多条ORDER BY 子句。虽然ORDER BY 子句似乎只是最后一条SELECT 语句的组成部分，但实际上MySQL将用它来排序所有SELECT 语句返回的所有结果。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C16_带聚集函数的联结]]></title>
    <url>%2F2018%2F04%2F14%2FC16-%E5%B8%A6%E8%81%9A%E9%9B%86%E5%87%BD%E6%95%B0%E7%9A%84%E8%81%94%E7%BB%93%2F</url>
    <content type="text"><![CDATA[聚集函数用来汇总数据。虽然至今为止聚集函数的所有例子只是从单个表汇总数据，但这些函数也可以与联结一起使用。123456789#检索所有客户及每个客户所下的订单数，下面使用了COUNT() 函数的代码可完成此工作。此SELECT 语句#使用INNER JOIN 将customers 和orders 表互相关联。GROUP BY 子句按客户分组数据，因此，函数调用#COUNT(orders.order_num) 对每个客户的订单计数，将它作为num_ord 返回SELECT customers.cust_name, customers.cust_id, COUNT(orders.order_num) AS num_ordFROM customers INNER JOIN orders ON customers.cust_id = orders.cust_idGROUP BY customers.cust_id;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C16_INNER JOIN, LEFT OUTER JOIN]]></title>
    <url>%2F2018%2F04%2F14%2FC16-INNER-JOIN-LEFT-OUTER-JOIN%2F</url>
    <content type="text"><![CDATA[自联结某物品（其ID为DTNTR ）存在问题，因此想知道生产该物品的供应商生产的其他物品是否也存在这些问题。此查询要求首先找到生产ID为DTNTR 的物品的供应商，然后找出这个供应商生产的其他物品1234567891011121314SELECT prod_id, prod_nameFROM productsWHERE vend_id = (SELECT vend_id FROM products WHERE prod_id = 'DTNTR');#内部的SELECT语句做了一个简单的检索，返回生产ID为DTNTR 的物品供应商的vend_id 。该ID用于外部#查询的WHERE 子句中，以便检索出这个供应商生产的所有物品#使用联结的相同查询SELECT p1.prod_id, p1.prod_nameFROM products AS p1, products AS p2WHERE p1.vend_id = p2.vend_id AND p2.prod_id = 'DTNTR'; 自然联结123456SELECT c.*, o.order_num, o.order_date, oi.prod_id, oi.quantity, OI.item_priceFROM customers AS c, orders AS o, orderitems AS oiWHERE c.cust_id = o.cust_id AND oi.order_num = o.order_num AND prod_id = 'FB'; 外部联结联结包含了那些在相关表中没有关联行的行。这种类型的联结称为外部联结。 在使用OUTER JOIN 语法时，必须使用RIGHT 或LEFT 关键字指定包括其所有行的表（RIGHT 指出的是OUTER JOIN 右边的表，而LEFT 指出的是OUTER JOIN 左边的表）。 存在两种基本的外部联结形式：左外部联结和右外部联结。它们之间的唯一差别是所关联的表的顺序不同。换句话说，左外部联结可通过颠倒FROM 或WHERE 子句中表的顺序转换为右外部联结。因此，两种类型的外部联结可互换使用，而究竟使用哪一种纯粹是根据方便而定。 12345678910#一个简单的内部联结。它检索所有客户及其订单SELECT customers.cust_id, orders.order_numFROM customers INNER JOIN orders ON customers.cust_id = orders.cust_id;#检索所有客户，包括那些没有订单的客户， 使用LEFT OUTER JOIN 从FROM 子句的左边表#（customers 表）中选择所有行SELECT customers.cust_id, orders.order_numFROM customers LEFT OUTER JOIN orders ON customers.cust_id = orders.cust_id;]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql crashcourse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C07_ocr.py_PIL-convert, point用法]]></title>
    <url>%2F2018%2F04%2F14%2FC07-ocr-py-PIL-convert-point%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[对于彩色图像，不管其图像格式是PNG，还是BMP，或者JPG，在PIL中，使用Image模块的open()函数打开后，返回的图像对象的模式都是“RGB”。而对于灰度图像，不管其图像格式是PNG，还是BMP，或者JPG，打开后，其模式为“L”。对于PNG、BMP和JPG彩色图像格式之间的互相转换都可以通过Image模块的open()和save()函数来完成。具体说就是，在打开这些图像时，PIL会将它们解码为三通道的“RGB”图像。用户可以基于这个“RGB”图像，对其进行处理。处理完毕，使用函数save()，可以将处理结果保存成PNG、BMP和JPG中任何格式。这样也就完成了几种格式之间的转换。同理，其他格式的彩色图像也可以通过这种方式完成转换。当然，对于不同格式的灰度图像，也可通过类似途径完成，只是PIL解码后是模式为“L”的图像。 Image模块的convert()函数，用于不同模式图像之间的转换。PIL中有九种不同模式。分别为1，L，P，RGB，RGBA，CMYK，YCbCr，I，F。convert()函数有三种形式的定义，它们定义形式如下： im.convert(mode) ⇒ image im.convert(“P”, **options) ⇒ image im.convert(mode, matrix) ⇒ image使用不同的参数，将当前的图像转换为新的模式，并产生新的图像作为返回值。 模式“1”12345678910111213141516171819&gt;&gt;&gt;from PIL import Image &gt;&gt;&gt; lena =Image.open("D:\\Code\\Python\\test\\img\\lena.jpg") &gt;&gt;&gt; lena.mode 'RGB' &gt;&gt;&gt; lena.getpixel((0,0)) (197, 111, 78) &gt;&gt;&gt; lena_1 = lena.convert("1") &gt;&gt;&gt; lena_1.mode '1' &gt;&gt;&gt; lena_1.size (512, 512) &gt;&gt;&gt;lena_1.getpixel((0,0)) 255 &gt;&gt;&gt; lena_1.getpixel((10,10)) 255 &gt;&gt;&gt;lena_1.getpixel((10,120)) 0&gt;&gt;&gt;lena_1.getpixel((130,120)) 255 模式“L”模式“L”为灰色图像，它的每个像素用8个bit表示，0表示黑，255表示白，其他数字表示不同的灰度。在PIL中，从模式“RGB”转换为“L”模式是按照下面的公式转换的：L = R 299/1000 + G 587/1000+ B * 114/1000 123456789lena_L =lena.convert("L") &gt;&gt;&gt; lena_L.mode 'L' &gt;&gt;&gt; lena_L.size (512, 512) &gt;&gt;&gt;lena.getpixel((0,0)) (197, 111, 78) &gt;&gt;&gt;lena_L.getpixel((0,0)) 132 Pointpoint()方法通过一个函数或者查询表对图像中的像素点进行处理 定义1im.point(table)⇒ imageim.point(function) ⇒ image返回给定查找表对应的图像像素值的拷贝。变量table为图像的每个通道设置256个值。如果使用变量function，其对应函数应该有一个参数。这个函数将对每个像素值使用一次，结果表格将应用于图像的所有通道。 12345678910&gt;&gt;&gt;from PIL import Image&gt;&gt;&gt; im01 = Image.open("D:\\Code\\Python\\test\\img\\test01.jpg") &gt;&gt;&gt;im_point_fun = im01.point(lambda i:i*1.2+10)&gt;&gt;&gt;im_point_fun.show()#图像im_point_fun比原图im01亮度增加了很多；因为lambda表达式中对原图的每个像素点的值都做了增#加操作。 定义2im.point(table,mode) ⇒ imageim.point(function, mode) ⇒ image与定义1一样，但是它会为输出图像指定一个新的模式。这个方法可以一步将模式为“L”和“P”的图像转换为模式为“1”的图像 1234567891011121314151617181920212223&gt;&gt;&gt;from PIL import Image&gt;&gt;&gt; im01 =Image.open("D:\\Code\\Python\\test\\img\\test01.jpg")&gt;&gt;&gt;r,g,b = im01.split()&gt;&gt;&gt;r.mode'L'&gt;&gt;&gt; im= r.point(lambda x:x*1.3+5, "1")&gt;&gt;&gt;im.show()&gt;&gt;&gt;im.getpixel((0,0))19#图像im为全白图；&gt;&gt;&gt; im= r.point(lambda x:1, "1")&gt;&gt;&gt;im.show()&gt;&gt;&gt;im.getpixel((0,0))1#图像im为全白图；&gt;&gt;&gt; im= r.point(lambda x:x*0, "1")&gt;&gt;&gt;im.show()&gt;&gt;&gt; im.getpixel((0,0))0#图像im为全黑图；]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C07_form.py_PIL]]></title>
    <url>%2F2018%2F04%2F14%2FC07-form-py-PIL%2F</url>
    <content type="text"><![CDATA[PIL (Python Image Library) 是 Python 平台处理图片的事实标准，兼具强大的功能和简洁的 API。PIL 的更新速度很慢，而且存在一些难以配置的问题，不推荐使用；而 Pillow 库则是 PIL 的一个分支，维护和开发活跃，Pillow 兼容 PIL 的绝大多数语法，推荐使用。 新建一个 Image 类的实例PIL 的主要功能定义在 Image 类当中，而 Image 类定义在同名的 Image 模块当中。使用 PIL 的功能，一般都是从新建一个 Image 类的实例开始。新建 Image 类的实例有多种方法。你可以用 Image 模块的 open() 函数打开已有的图片档案，也可以处理其它的实例，或者从零开始构建一个实例。 12345678from PIL import ImagesourceFileName = "source.png"avatar = Image.open(sourceFileName)# open() 方法打开了 source.png 这个图像，构建了名为 avatar 的实例。如果打开失败，则会抛出IOError 异常。#使用 show() 方法来查看实例。注意，PIL 会将实例暂存为一个临时文件，而后打开它。avatar.show() 查看实例的属性Image 类的实例有 5 个属性，分别是： format: 以 string 返回图片档案的格式（JPG, PNG, BMP, None, etc.）；如果不是从打开文件得到的实例，则返回 None。 mode: 以 string 返回图片的模式（RGB, CMYK, etc.）；完整的列表参见 官方说明·图片模式列表 size: 以二元 tuple 返回图片档案的尺寸 (width, height) palette: 仅当 mode 为 P 时有效，返回 ImagePalette 示例 info: 以字典形式返回示例的信息 12print avatar.format, avatar.size, avatar.mode#图片的格式 PNG、图片的大小 (400, 400) 和图片的模式 RGB 图片 IO - 转换图片格式Image 模块提供了 open() 函数打开图片档案，Image 类则提供了 save() 方法将图片实例保存为图片档案。 save() 函数可以以特定的图片格式保存图片档案。比如 save(‘target.jpg’, ‘JPG’) 将会以 JPG 格式将图片示例保存为 target.jpg。不过，大多数时候也可以省略图片格式。此时，save() 方法会根据文件扩展名来选择相应的图片格式。 1234567891011import os, sysfrom PIL import Imagefor infile in sys.argv[1:]: f, e = os.path.splitext(infile) outfile = f + ".jpg" if infile != outfile: try: Image.open(infile).save(outfile) except IOError: print "cannot convert", infile 制作缩略图Image 类的 thumbnail() 方法可以用来制作缩略图。它接受一个二元数组作为缩略图的尺寸，然后将示例缩小到指定尺寸。 12345678910111213import os, sysfrom PIL import Imagefor infile in sys.argv[1:]: outfile = os.path.splitext(infile)[0] + ".thumbnail" if infile != outfile: try: im = Image.open(infile) x, y = im.size #用 im.size 获取原图档的尺寸 im.thumbnail((x//2, y//2)) im.save(outfile, "JPEG") except IOError: print "cannot create thumbnail for", infile 剪裁图档按照 horizon 和 vertic 两个变量切割当前目录下所有图片（包括子目录）。 123456789101112131415161718192021222324import Image as imgimport osimgTypes = ['.png','.jpg','.bmp']horizon = 8vertic = 1for root, dirs, files in os.walk('.'): for currentFile in files: crtFile = root + '\\' + currentFile if crtFile[crtFile.rindex('.'):].lower() in imgTypes: crtIm = img.open(crtFile) crtW, crtH = crtIm.size hStep = crtW // horizon vStep = crtH // vertic for i in range(vertic): for j in range(horizon): crtOutFileName = crtFile[:crtFile.rindex('.')] + \ '_' + str(i) + '_' + str(j)\ + crtFile[crtFile.rindex('.'):].lower() box = (j * hStep, i * vStep, (j + 1) * hStep, (i + 1) * vStep) cropped = crtIm.crop(box) cropped.save(crtOutFileName) 变形与粘贴transpose() 方法可以将图片左右颠倒、上下颠倒、旋转 90°、旋转 180° 或旋转 270°。paste() 方法则可以将一个 Image 示例粘贴到另一个 Image 示例上。 尝试将一张图片的左半部分截取下来，左右颠倒之后旋转 180°；将图片的右半边不作更改粘贴到左半部分；最后将修改过的左半部分粘贴到右半部分。 123456789101112131415161718192021222324252627282930313233from PIL import ImageimageFName = 'source.png'def iamge_transpose(image): ''' Input: a Image instance Output: a transposed Image instance Function: * switches the left and the right part of a Image instance * for the left part of the original instance, flips left and right\ and then make it upside down. ''' xsize, ysize = image.size xsizeLeft = xsize // 2 # while xsizeRight = xsize - xsizeLeft boxLeft = (0, 0, xsizeLeft, ysize) boxRight = (xsizeLeft, 0, xsize, ysize) boxLeftNew = (0, 0, xsize - xsizeLeft, ysize) boxRightNew = (xsize - xsizeLeft, 0, xsize, ysize) partLeft = image.crop(boxLeft).transpose(Image.FLIP_LEFT_RIGHT).\ transpose(Image.ROTATE_180) partRight = image.crop(boxRight) image.paste(partRight, boxLeftNew) image.paste(partLeft, boxRightNew) return imageavatar = Image.open(imageFName)avatar = iamge_transpose(avatar)avatar.show() 以 xsize 和 ysize 接收图片的宽和高，然后以 xsizeLeft 计算得到左半边图片的大小。需要注意的是，我们构建了四个元组，并命名为盒子。这个盒子用直角坐标的值在 image 的画布上框定了一个区域。注意，Image 模块以图片的左上角为直角坐标原点，向右为 x 轴正方向，向下为 y 轴正方向。元组中的前两个数，代表区域左上角的坐标值；后两个数代表区域右下角的坐标值。 接下来的代码相当易懂。我们先用 crop() 方法将原图 boxLeft 的区域（也就是原图的左半边）切下来，然后用 transpose() 方法先后进行左右颠倒和旋转 180° 的工作，并最周公将它保存在 partLeft 这个实例中。而 partRight 的操作更为简单。 函数的最后，我们用 paste() 方法，将前两步得到的 partLeft 和 partRight 分别粘贴到指定的区域；并最终返回 image 示例。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C06_login.py_glob]]></title>
    <url>%2F2018%2F04%2F14%2FC06-login-py-glob%2F</url>
    <content type="text"><![CDATA[基本用法 glob.glob（pathname), 返回所有匹配的文件路径列表。它只有一个参数pathname，定义了文件路径匹配规则，这里可以是绝对路径，也可以是相对路径。 glob.iglob(pathname), 获取一个可编历对象，使用它可以逐个获取匹配的文件路径名。与glob.glob()的区别是：glob.glob同时获取所有的匹配路径，而glob.iglob一次只获取一个匹配路径。 列出子目录中的文件，必须把子目录包含在模式中。 12345678import glob# get all py filesfiles = glob.glob('*.py')print files# Output# ['arg.py', 'g.py', 'shut.py', 'test.py'] 123456789101112131415import itertools as it, globdef multiple_file_types(*patterns): return it.chain.from_iterable(glob.glob(pattern) for pattern in patterns)for filename in multiple_file_types("*.txt", "*.py"): # add as many filetype arguements print filename# output#=========## test.txt# arg.py# g.py# shut.py# test.py 12345678910111213141516import itertools as it, glob, osdef multiple_file_types(*patterns): return it.chain.from_iterable(glob.glob(pattern) for pattern in patterns)for filename in multiple_file_types("*.txt", "*.py"): # add as many filetype arguements realpath = os.path.realpath(filename) print realpath# output#=========## C:\xxx\pyfunc\test.txt# C:\xxx\pyfunc\arg.py# C:\xxx\pyfunc\g.py# C:\xxx\pyfunc\shut.py# C:\xxx\pyfunc\test.py]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C05_search2.py_csv]]></title>
    <url>%2F2018%2F04%2F14%2FC05-search2-py-csv%2F</url>
    <content type="text"><![CDATA[对于大多数的CSV格式的数据读写问题，都可以使用 csv 库。 例如：假设你在一个名叫stocks.csv文件中有一些股票市场数据，就像这样：12345678Symbol,Price,Date,Time,Change,Volume"AA",39.48,"6/11/2007","9:36am",-0.18,181800"AIG",71.38,"6/11/2007","9:36am",-0.15,195500"AXP",62.58,"6/11/2007","9:36am",-0.46,935000"BA",98.31,"6/11/2007","9:36am",+0.12,104800"C",53.08,"6/11/2007","9:36am",-0.25,360900"CAT",78.29,"6/11/2007","9:36am",-0.23,225400 读取csv数据row[0] 访问Symbol， row[4] 访问Change1234567import csvwith open('stocks.csv') as f: f_csv = csv.reader(f,delimiter='\t') headers = next(f_csv) for row in f_csv: # Process row ... row.Symbol 和 row.Change 代替下标访问123456789101112131415161718from collections import namedtuplewith open('stock.csv') as f: f_csv = csv.reader(f) headings = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) #可能有一个包含非法标识符的列头行 Row = namedtuple('Row', headings) for r in f_csv: row = Row(*r) # Process row ...#或者 row['Symbol']， row['Change']import csvwith open('stocks.csv') as f: f_csv = csv.DictReader(f) for row in f_csv: # process row ... csv.DictReader, csv.DictWriter用法12345678910111213141516171819202122232425FIELDS = ['Name', 'Sex', 'E-mail', 'Blog'] # DictWriter csv_file = open('test.csv', 'wb') writer = csv.DictWriter(csv_file, fieldnames=FIELDS) # write header writer.writerow(dict(zip(FIELDS, FIELDS))) d = &#123;&#125; d['Name'] = 'Qi' d['Sex'] = 'Male' d['E-mail'] = 'redice@163.com' d['Blog'] = 'http://www.redicecn.com' writer.writerow(d) csv_file.close() # DictReader # A easier way for skipping the header # Usually we need a extra flag variables for d in csv.DictReader(open('test.csv', 'rb')): print d # Output: # &#123;'Blog': 'http://www.redicecn.com', 'E-mail': 'redice@163.com', 'Name': 'Qi', 'Sex': 'Male'&#125; 写入csv数据123456789101112131415161718192021222324252627#创建writer对象headers = ['Symbol','Price','Date','Time','Change','Volume']rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800), ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500), ('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000), ]with open('stocks.csv','w') as f: f_csv = csv.writer(f) f_csv.writerow(headers) f_csv.writerows(rows)#创建DictWriter对象headers = ['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume']rows = [&#123;'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.18, 'Volume':181800&#125;, &#123;'Symbol':'AIG', 'Price': 71.38, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.15, 'Volume': 195500&#125;, &#123;'Symbol':'AXP', 'Price': 62.58, 'Date':'6/11/2007', 'Time':'9:36am', 'Change':-0.46, 'Volume': 935000&#125;, ]with open('stocks.csv','w') as f: f_csv = csv.DictWriter(f, headers) f_csv.writeheader() f_csv.writerows(rows) csv数据进行类型转换123456789field_types = [ ('Price', float), ('Change', float), ('Volume', int) ]with open('stocks.csv') as f: for row in csv.DictReader(f): row.update((key, conversion(row[key])) for key, conversion in field_types) print(row)]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C04_process_test.py_multiprocessing]]></title>
    <url>%2F2018%2F04%2F14%2FC04-process-test-py-multiprocessing%2F</url>
    <content type="text"><![CDATA[multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可。 如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。 当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。 创建管理进程模块： Process（用于创建进程模块） Pool（用于创建管理进程池） Queue（用于进程通信，资源共享） Value，Array（用于进程通信，资源共享） Pipe（用于管道通信） Manager（用于资源共享） 同步子进程模块： Condition Event Lock RLock Semaphore]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C04_threaded_crawler.py_threading]]></title>
    <url>%2F2018%2F04%2F14%2FC04-threaded-crawler-py-threading%2F</url>
    <content type="text"><![CDATA[创建threading.Thread的子类来包装一个线程对象 threading.Thread类的使用： 1，在自己的线程类的init里调用threading.Thread.init(self, name = threadname) Threadname为线程的名字2， run()，通常需要重写，编写代码实现做需要的功能。 3，getName()，获得线程对象名称 4，setName()，设置线程对象名称 5，start()，启动线程 6，join([timeout])，等待另一线程结束后再运行。 7，setDaemon(bool)，设置子线程是否随主线程一起结束，必须在start()之前调用。默认为False。 8，isDaemon()，判断线程是否随主线程一起结束。 9，isAlive()，检查线程是否在运行中。 12345678910111213141516171819202122232425262728293031323334353637import threadingimport timeclass timer(threading.Thread): #The timer class is derived from the class threading.Thread def __init__(self, num, interval): threading.Thread.__init__(self) self.thread_num = num self.interval = interval self.thread_stop = False def run(self): #Overwrite run() method, put what you want the thread do here while not self.thread_stop: print 'Thread Object(%d), Time:%s\n' %(self.thread_num, time.ctime()) time.sleep(self.interval) def stop(self): self.thread_stop = True def test(): thread1 = timer(1, 1) thread2 = timer(2, 2) thread1.start() thread2.start() time.sleep(10) thread1.stop() thread2.stop() return if __name__ == '__main__': test()假设两个线程对象t1和t2都要对num=0进行增1运算，t1和t2都各对num修改10次，num的最终的结果应该为20。但是由于是多线程访问，有可能出现下面情况：在num=0时，t1取得num=0。系统此时把t1调度为”sleeping”状态，把t2转换为”running”状态，t2页获得num=0。然后t2对得到的值进行加1并赋给num，使得num=1。然后系统又把t2调度为”sleeping”，把t1转为”running”。线程t1又把它之前得到的0加1后赋值给num。这样，明明t1和t2都完成了1次加1工作，但结果仍然是num=1。上面的case描述了多线程情况下最常见的问题之一：数据共享。当多个线程都要去修改某一个共享数据的时候，我们需要对数据访问进行同步。 简单的同步 最简单的同步机制就是“锁”。锁对象由threading.RLock类创建。线程可以使用锁的acquire()方法获得锁，这样锁就进入“locked”状态。每次只有一个线程可以获得锁。如果当另一个线程试图获得这个锁的时候，就会被系统变为“blocked”状态，直到那个拥有锁的线程调用锁的release()方法来释放锁，这样锁就会进入“unlocked”状态。“blocked”状态的线程就会收到一个通知，并有权利获得锁。如果多个线程处于“blocked”状态，所有线程都会先解除“blocked”状态，然后系统选择一个线程来获得锁，其他的线程继续沉默（“blocked”）。 Python的threading module是在建立在thread module基础之上的一个module，在threading module中，暴露了许多thread module中的属性。在thread module中，python提供了用户级的线程同步工具“Lock”对象。而在threading module中，python又提供了Lock对象的变种: RLock对象。RLock对象内部维护着一个Lock对象，它是一种可重入的对象。对于Lock对象而言，如果一个线程连续两次进行acquire操作，那么由于第一次acquire之后没有release，第二次acquire将挂起线程。这会导致Lock对象永远不会release，使得线程死锁。RLock对象允许一个线程多次对其进行acquire操作，因为在其内部通过一个counter变量维护着线程acquire的次数。而且每一次的acquire操作必须有一个release操作与之对应，在所有的release操作完成之后，别的线程才能申请该RLock对象。 12345678910111213141516171819202122import threadingimport timemylock=threading.RLock()num=0f=file('test_result.txt','w')class dog(theading.Thread): def __init__(self,name): theading.Thread,__init__(self) self.name=name def run(self): global num while num&lt;=5: time.sleep(0.5) mylock.acquire() print "Th(%s) locked, number: %d\n" %(self.name, num) f.write(self.name+" "+str(num)+'\n') print "Th(%s) released, number: %d\n" %(self.name, num) mylock.release() num += 1 条件同步 锁只能提供最基本的同步。假如只在发生某些事件时才访问一个“临界区”，这时需要使用条件变量 Condition。Condition对象是对Lock对象的包装，在创建Condition对象时，其构造函数需要一个Lock对象作为参数，如果没有这个Lock对象参数，Condition将在内部自行创建一个Rlock对象。在Condition对象上，当然也可以调用acquire和release操作，因为内部的Lock对象本身就支持这些操作。但是Condition的价值在于其提供的wait和notify的语义。 条件变量是如何工作的呢？首先一个线程成功获得一个条件变量后，调用此条件变量的wait()方法会 导致这个线程释放这个锁，并进入“blocked”状态，直到另一个线程调用同一个条件变量的notify()方法来唤醒那个进入“blocked”状态的线程。如果调用这个条件变量的notifyAll()方法的话就会唤醒所有的在等待的线程。 如果程序或者线程永远处于“blocked”状态的话，就会发生死锁。所以如果使用了锁、条件变量等同步机制的话，一定要注意仔细检查，防止死锁情况的发生。对于可能产生异常的临界区要使用异常处理机制中的finally子句来保证释放锁。等待一个条件变量的线程必须用notify()方法显式的唤醒，否则就永远沉默。保证每一个wait()方法调用都有一个相对应的notify()调用，当然也可以调用notifyAll()方法以防万一。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import threadingimport time con = threading.Condition()x=0 class Producer(threading.Thread): def __init__(self, name): threading.Thread.__init__(self) self.name = name def run(self): global x con.acquire() if x&gt;0: con.wait() else: for i in range(5): x += 1 print "producing... "+str(x) con.notify() print x con.release() class Consumer(threading.Thread): def __init__(self, name): threading.Thread.__init__(self) self.name = name def run(self): global x con.acquire() if x==0: print "consumer wait" con.wait() else: for i in range(5): x -= 1 print "consuming... "+str(x) con.notify() print x con.release() def test(): print "start consumer\n" th1 = Consumer("consumer") print "start producer\n" th2 = Producer("producer") th1.start() th2.start() th1.join() th2.join() if __name__ == '__main__': test() 同步队列 Python中的Queue对象也提供了对线程同步的支持。使用Queue对象可以实现多个生产者和多个消费 者形成的FIFO的队列。 生产者将数据依次存入队列，消费者依次从队列中取出数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import threadingimport timeimport Queueimport random #producerclass Producer(threading.Thread): def __init__(self, queue): threading.Thread.__init__(self) self.data = queue def run(self): for i in range(5): print "%s is producing %d to the queue!\n" %(self.getName(), i) self.data.put(i) time.sleep(random.randrange(10)/5) print "%s finished!\n" %(self.getName()) #consumerclass Consumer(threading.Thread): def __init__(self, queue): threading.Thread.__init__(self) self.data = queue def run(self): for i in range(5): something = self.data.get() print "%s is consuming. %d in the queue is consumed!\n" %(self.getName(), something) time.sleep(random.randrange(10)) print "%s finished!\n" %(self.getName()) def test(): queue = Queue.Queue() th1 = Producer(queue) th2 = Consumer(queue) th1.start() th2.start() th1.join() th2.join() print "all threads terminate!\n" if __name__ == '__main__': test() join的用法123456789101112131415161718192021222324252627282930313233343536import threadingimport timedef context(tJoin): print 'in threadContext.' tJoin.start() # 将阻塞tContext直到threadJoin终止。 tJoin.join() # tJoin终止后继续执行。 print 'out threadContext.'def join(): print 'in threadJoin.' time.sleep(1) print 'out threadJoin.'tJoin = threading.Thread(target=join)tContext = threading.Thread(target=context, args=(tJoin,))tContext.start()#结果：in threadContext.in threadJoin.out threadJoin.out threadContext.&gt; tContext = threading.Thread(target=context, args=(tJoin,))&gt; tContext.start()# tJoin = threading.Thread(target=join)执行后，只是创建了一个线程对象tJoin，但并未启动该线程,这两# 句执行后，创建了另一个线程对象tContext并启动该线程（打印in threadContext.），同时将tJoin线程# 对象作为参数传给context函数，在context函数中，启动了tJoin这个线程，同时该线程又调用了join()函# 数（tJoin.join()），那tContext线程将等待tJoin这线程执行完成后，才能继续tContext线程后面的，所以# 先执行join()函数,tJoin线程执行结束后，继续执行tContext线程，于是打印输出了out threadContext.，# 于是就看到我们上面看到的输出结果，并且无论执行多少次，结果都是这个顺序。但如果将context()函# 数中tJoin.join()这句注释掉，再执行该程序，打印输出的结果顺序就不定了，因为此时这两线程就是并# 发执行的。]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C03_disk_cached.py_shutil]]></title>
    <url>%2F2018%2F04%2F14%2FC03-disk-cached-py-shutil%2F</url>
    <content type="text"><![CDATA[os模块提供了对目录或者文件的新建/删除/查看文件属性，还提供了对文件以及目录的路径操作。比如说：绝对路径，父目录…… 但是，os文件的操作还应该包含移动 复制 打包 压缩 解压等操作，这些os模块都没有提供，shutil则就是对os中文件操作的补充， shutil是shell utility的缩写。 shutil 模块shutil.copyfile( src, dst) 从源src复制到dst中去。当然前提是目标地址是具备可写权限。抛出的异常信息为IOException. 如果当前的dst已存在的话就会被覆盖掉shutil.move( src, dst) 移动文件或重命名shutil.copymode( src, dst) 只是会复制其权限其他的东西是不会被复制的shutil.copystat( src, dst) 复制权限、最后访问时间、最后修改时间shutil.copy( src, dst) 复制一个文件到一个文件或一个目录shutil.copy2( src, dst) 在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了，类似于cp –p的东西shutil.copy2( src, dst) 如果两个位置的文件系统是一样的话相当于是rename操作，只是改名；如果是不在相同的文件系统的话就是做move操作shutil.copytree( olddir, newdir, True/Flase)把olddir拷贝一份newdir，如果第3个参数是True，则复制目录时将保持文件夹下的符号连接，如果第3个参数是False，则将在复制的目录下生成物理副本来替代符号连接shutil.rmtree( src ) 递归删除一个目录以及目录内的所有内容 os 模块os.sep 可以取代操作系统特定的路径分隔符。windows下为 ‘\‘os.name 字符串指示你正在使用的平台。比如对于Windows，它是’nt’，而对于Linux/Unix用户，它是 ‘posix’os.getcwd() 函数得到当前工作目录，即当前Python脚本工作的目录路径os.getenv() 获取一个环境变量，如果没有返回noneos.putenv(key, value) 设置一个环境变量值os.listdir(path) 返回指定目录下的所有文件和目录名os.remove(path) 函数用来删除一个文件os.system(command) 函数用来运行shell命令os.linesep 字符串给出当前平台使用的行终止符。例如，Windows使用 ‘\r\n’，Linux使用 ‘\n’ 而Mac使用 ‘\r’os.path.split(path) 函数返回一个路径的目录名和文件名os.path.isfile() 和os.path.isdir()函数分别检验给出的路径是一个文件还是目录os.path.exists() 函数用来检验给出的路径是否真地存在os.curdir 返回当前目录 (‘.’)os.mkdir(path) 创建一个目录os.makedirs(path) 递归的创建目录os.chdir(dirname) 改变工作目录到dirnameos.path.getsize(name) 获得文件大小，如果name是目录返回0Los.path.abspath(name) 获得绝对路径os.path.normpath(path) 规范path字符串形式os.path.splitext() 分离文件名与扩展名os.path.join(path,name) 连接目录与文件名或目录os.path.basename(path) 返回文件名os.path.dirname(path) 返回文件路径os.walk(top,topdown=True,onerror=None) 遍历迭代目录os.rename(src, dst) 重命名file或者directory src到dst 如果dst是一个存在的directory, 将抛出OSError. 在Unix, 如果dst在存且是一个file, 如果用户有权限的话，它将被安静的替换. 操作将会失败在某些Unix 中如果src和dst在不同的文件系统中. 如果成功, 这命名操作将会是一个原子操作 (这是POSIX 需要). 在 Windows上, 如果dst已经存在, 将抛出OSError，即使它是一个文件. 在unix，Windows中有效。os.renames(old, new) 递归重命名文件夹或者文件。像rename()]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C03_mongo_cache.py_pymongo]]></title>
    <url>%2F2018%2F04%2F14%2FC03-mongo-cache-py-pymongo%2F</url>
    <content type="text"><![CDATA[基本用法 123456789101112131415161718192021222324252627282930313233import pymongoclient = pymongo.MongoClient(host='localhost', port=27017)db = client.cache# 指定为test 数据库collection = db.webpage#MongoDB 的每个数据库又包含了许多集合 Collection，也就类似与关系型数据库中的表condition = &#123;'name': 'Kevin'&#125;student = collection.find_one(condition)student['age'] = 25result = collection.update(condition, student)或者result = collection.update(condition, &#123;'$set': student&#125;)#只更新 student 字典内存在的字段，如果其原先还有其他字段则不会更新，也不会删除。而如果不用 $set 的话则会把之前的数据全部用 student 字典替换，如果原本存在其他的字段则会被删除。condition = &#123;'age': &#123;'$gt': 20&#125;&#125;result = collection.update_one(condition, &#123;'$inc': &#123;'age': 1&#125;&#125;)print(result)print(result.matched_count, result.modified_count)#指定查询条件为年龄大于 20，然后更新条件为 &#123;'$inc': &#123;'age': 1&#125;&#125;，也就是年龄加 1，执行之后会将第一条符合条件的数据年龄加 1# find_and_modify用法class MongoQueue: def pop(self): """Get an outstanding URL from the queue and set its status to processing. If the queue is empty a KeyError exception is raised. """ record = self.db.crawl_queue.find_and_modify( query=&#123;'status': self.OUTSTANDING&#125;, update=&#123;'$set': &#123;'status': self.PROCESSING, 'timestamp': datetime.now()&#125;&#125; ) if record: return record['_id'] else: self.repair() raise KeyError() mongodb存储二进制数据 BSON是一种类json的一种二进制形式的存储格式，简称Binary JSON，它和JSON一样，支持内嵌的文档对象和数组对象，但是BSON有JSON没有的一些数据类型，如Date和BinData类型。{“hello”:”world”} 这是一个BSON的例子，其中”hello”是key name，它一般是cstring类型，字节表示是cstring::= (byte) “/x00” ,其中表示零个或多个byte字节，/x00表示结束符;后面的”world”是value值，它的类型一般是、string,double,array,binarydata等类型。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import pymongoimport bson.binaryfrom pymongo import MongoClientfrom cStringIO import StringIOdef insertFile(): client = MongoClient('localhost', 27017) #获得一个database db = client.MongoFile #获得一个collection coll = db.image filename = 'F:/测试数据/hehe.jpg'.decode('utf-8') with open (filename,'rb') as myimage: content = StringIO(myimage.read()) coll.save(dict( content= bson.binary.Binary(content.getvalue()), filename = 'hehe.jpg' )) def getFile(): client = MongoClient('localhost', 27017) #获得一个database db = client.MongoFile #获得一个collection coll = db.image data = coll.find_one(&#123;'filename':'hehe.jpg'&#125;) out = open('F:/测试数据/test4.jpg'.decode('utf-8'),'wb') out.write(data['content']) out.close()getFile()#Here is an example of how to save some data to MongoDB and then load it:&gt;&gt;&gt; url = 'http://example.webscraping.com/view/United-Kingdom-239'&gt;&gt;&gt; html = '...'&gt;&gt;&gt; db = client.cache &gt;&gt;&gt; db.webpage.insert(&#123;'url': url, 'html': html&#125;)ObjectId('5518c0644e0c87444c12a577')&gt;&gt;&gt; db.webpage.find_one(url=url)&#123;u'_id': ObjectId('5518c0644e0c87444c12a577'), u'html': u'...', u'url': u'http://example.webscraping.com/view/United-Kingdom-239'&#125;#A problem with the preceding example is that if we now insert another document #with the same URL, MongoDB will happily insert it for us, as follows:&gt;&gt;&gt; db.webpage.insert(&#123;'url': url, 'html': html&#125;)&gt;&gt;&gt; db.webpage.find(url=url).count()2#Now we have multiple records for the same URL when we are only interested in #storing the latest data. To prevent duplicates, we can set the ID to the URL and #perform upsert, which means updating the existing record if it exists; otherwise, #insert a new one, as shown here:&gt;&gt;&gt; self.db.webpage.update(&#123;'_id': url&#125;, &#123;'$set': &#123;'html': html&#125;&#125;, upsert=True)&gt;&gt;&gt; db.webpage.update(&#123;'_id': url&#125;, &#123;'$set': &#123;'html': ''&#125;&#125;, upsert=True)&gt;&gt;&gt; db.webpage.find_one(&#123;'_id': url&#125;)&#123;u'_id': u'http://example.webscraping.com/view/United-Kingdom-239', u'html': u'...'&#125;#A timestamp index was created in the constructor. This is a handy MongoDB feature that will #automatically delete records in a specified number of seconds after the given timestamp. This means#that we do not need to manually check whether a record is still valid, as in the DiskCache class.&gt;&gt;&gt;expires=timedelta(days=30)&gt;&gt;&gt;self.db.webpage.create_index('timestamp',expireAfterSeconds=expires.total_seconds()) zlib压缩与解压缩1234567891011121314151617181920212223242526272829303132import zlibdef compress(infile, dst, level=9): infile = open(infile, 'rb') dst = open(dst, 'wb') compress = zlib.compressobj(level) data = infile.read(1024) while data: dst.write(compress.compress(data)) data = infile.read(1024) dst.write(compress.flush())def decompress(infile, dst): infile = open(infile, 'rb') dst = open(dst, 'wb') decompress = zlib.decompressobj() data = infile.read(1024) while data: dst.write(decompress.decompress(data)) data = infile.read(1024) dst.write(decompress.flush()) if __name__ == "__main__": infile = "1.txt" dst = "1.zlib.txt" compress(infile, dst) infile = "1.zlib.txt" dst = "2.txt" decompress(infile, dst) print "done~"compressobj返回一个压缩对象，用来压缩不能一下子读入内存的数据流。 level 从9到-1表示压缩等级，其中1最快但压缩度最小，9最慢但压缩度最大，0不压缩，默认是-1大约相当于与等级6，是一个压缩速度和压缩度适中的level。 picklepickle提供了一个简单的持久化功能。可以将对象以文件的形式存放在磁盘上。pickle模块只能在python中使用，python中几乎所有的数据类型（列表，字典，集合，类等）都可以用pickle来序列化 pickle.dump(obj, file[, protocol]) 序列化对象，并将结果数据流写入到文件对象中。参数protocol是序列化模式，默认值为0，表示以文本的形式序列化。protocol的值还可以是1或2，表示以二进制的形式序列化。 dumps()函数执行和dump() 函数相同的序列化，但是与dump不同的dumps并不将转换后的字符串写入文件，而是将所得到的转换后的数据以字符串的形式返回。 pickle.load(file) 反序列化对象。将文件中的数据解析为一个Python对象。 loads()函数执行和load()函数一样的反序列化。 loads接受一个字符串参数，将字符串解码成为python的数据类型，函数loads和dumps进行的是互逆的操作。12345678910111213141516171819202122232425import cPickle #序列化到文件obj = 123,"abcdedf",["ac",123],&#123;"key":"value","key1":"value1"&#125;print obj#输出：(123, 'abcdedf', ['ac', 123], &#123;'key1': 'value1', 'key': 'value'&#125;)#r 读写权限 r b 读写到二进制文件f = open(r"d:\a.txt","r ")cPickle.dump(obj,f)f.close()f = open(r"d:\a.txt")print cPickle.load(f)#输出：(123, 'abcdedf', ['ac', 123], &#123;'key1': 'value1', 'key': 'value'&#125;) #序列化到内存（字符串格式保存），然后对象可以以任何方式处理如通过网络传输obj1 = cPickle.dumps(obj)print type(obj1)#输出：&lt;type 'str'&gt;print obj1#输出：python专用的存储格式obj2 = cPickle.loads(obj1)print type(obj2)#输出：&lt;type 'tuple'&gt;print obj2#输出：(123, 'abcdedf', ['ac', 123], &#123;'key1': 'value1', 'key': 'value'&#125;)]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C03_downloader.py_datetime]]></title>
    <url>%2F2018%2F04%2F14%2FC03-downloader-py-datetime%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718from datetime import datetime&gt;&gt;&gt; today=datetime.today()&gt;&gt;&gt; today.date()datetime.date(2018, 4, 2)&lt;!-- more --&gt;&gt;&gt;&gt; today.time()datetime.time(4, 52, 20, 254000)&gt;&gt;&gt; next_month=today.replace(month=today.month+1)&gt;&gt;&gt; next_monthdatetime.datetime(2018, 5, 2, 4, 52, 20, 254000)&gt;&gt;&gt; next_month.strftime('%Y-%m-%d %H:%M:%S')'2018-05-02 04:52:20'&gt;&gt;&gt; import time&gt;&gt;&gt; t=time.mktime(today.timetuple()) #将一个datetime对象转成时间戳，很遗憾的是python并没直接提供这个方法，但是提供了一个timetuple()方法，它返回一个time.struct_time对象，通过它我们可以构造出时间戳&gt;&gt;&gt; t1522669940.0]]></content>
      <categories>
        <category>book notes</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web scraper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask 博客配置]]></title>
    <url>%2F2018%2F04%2F14%2Fflask-%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[服务器，域名，DNSvps: vultr debian7 domain: Freenom ，具体操作可见此处(需科学上网) DNS: cloudfare, 具体操作可见此处(需科学上网)，这篇文章介绍的是cloudXNS, 也适用于cloudfare 服务器环境设置 工具 git bash 或者 putty，git bash是windows上安装git时顺带安装的bash模拟器，后续还用到git,所以直接安装git 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#此处ip是vps的ip地址， 22是ssh连接的默认端口号， 如果没有修改过默认端口，这个-p可以省略不写了ssh -p 22 root@ip#输入vps的密码后就可以登录了，此时建议换一个密码[root@vultr:~]passwd#新建一个普通用户,名为user, ‘adduser’也可以新建用户， 但是创建的用户是三无用户，无家目录/无bash/无密码，所以此处用的是'useradd',记性不好，这两个命令常常搞错。。[root@vultr:~]# user#创建密码[root@vultr:~]passwd user#此时新用户创建完成， 还需把它加入sudoers列表中，让它可以使用root的命令[root@vultr:~]apt-get install sudo #debian7 上没有默认安装sudo命令[root@vultr:~]visudo...root ALL=(ALL) ALLuser ALL=(ALL) ALL #新增加这一行就Ok了#切换到user用户[root@vultr:~]su - user[user@vultr:~]$#这个博客是基于flask,python3.5写的，所以还得安装python3.5, debian7默认已安装的是python2.7[user@vultr:~]$sudo apt-get update[user@vultr:~]$sudo dpkg -l python* #可以看到最新的python是到3.1#安装依赖[user@vultr:~]$sudo apt-get install -y build-essential libncurses5-dev libncursesw5-dev libreadline6-dev libdb5.1-dev libgdbm-dev libsqlite3-dev libssl-dev libbz2-dev libexpat1-dev liblzma-dev zlib1g-dev#下载安装包[user@vultr:~]$wget --no-check-certificate https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tgz#编译安装[user@vultr:~]$tar xzvf Python-3.5.1.tgz[user@vultr:~]$cd Python-3.5.1.tgz[user@vultr:~]$./configure --prefix=/usr/local/python3 #创建 Makefile 这个文件，prefix是安装路径[user@vultr:~]$make all #all会编译所有子模块，如sqlite3等[user@vultr:~]$sudo make install#成功安装后应该可以看到一下信息Installing collected packages: setuptools, pipSuccessfully installed pip-7.1.2 setuptools-18.2#按照提示升级pip3[user@vultr:~]$pip3 install --upgrade pip#为当前用户user添加路径[user@vultr:~]$vim ~/.bashrc添加 export PATH=$PATH:/usr/local/python3/bin[user@vultr:~]$source ~/.bashrc #将当前bashrc设置读入目前的bash环境中[user@vultr:~]$python3 --verison #当前python3的版本#为python3, pip3, virtualenv设置软链接, 这里没有把原来的python命令删除[user@vultr:~]$sudo ln -s /usr/local/python3/bin/python3 /usr/bin/python3[user@vultr:~]$sudo ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3[user@vultr:~]$sudo ln -s /usr/local/python3/bin/virtualenv /usr/bin/virtualenv #/usr/bin 所以一般用户用的指令放的地方 安装数据库redis123456789101112131415161718#redis安装，方法一$wget http://download.redis.io/releases/redis-stable.tar.gz$ xzf redis-stable.tar.gz$cd redis-stable$make$make test #run the test after build$sudo make install #redis安装， 方法二#其实直接可以用apt-get安装啦$sudo apt-get install redis-server#安装完成后， redis会自动启动$ps -aux | grep redis #检查redis进程$netstat -nlt | grep 6379 #检查redis网络监听端口$sudo /etc/init.d/redis-server status # /etc/init.d/ #系统服务启动的接口放在这个目录下 安装postgresql123456789101112131415#添加postgrelsql apt repository$sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt/ wheezy-pgdg main" &gt;&gt; /etc/apt/sources.list.d/pgdg.list'#导入密匙$wget -q https://www.postgresql.org/media/keys/ACCC4CF8.asc -O - | sudo apt-key add -#安装$sudo apt-get update$sudo apt-get install postgresql postgresql-contrib#默认情况下安装PostgreSQL数据库服务器后，它将创建一个用户'postgres'，角色为'postgres'。 它还创建一个名称为“postgres”的系统帐户#登陆$sudo su - postgres$psql 上传文件到vps一般来说有两种方式， 一种是scp, 一种git clone 123456789101112#从本地复制目录到远程服务器， -r 递归复制整个目录$scp -r local_folder remote_username@remote_ip:remote_folder #此处remote_folder为dir=/home/&#123;user&#125;/blog，local_folder为your_blogname#如果是git clone的话，先注册个git hub 账号，然后创建一个repository,把本地文件push到这个库里$git init $git add .$git commit -m 'upload'$git configure --global$git remote add origin https://github...$git push -u origin master#感觉用git clone比较快点，而且可以随时随地上传，比较方便 安装虚拟环境把文件上传到vps后，就需要安装python3的虚拟环境了 12345678#在当前目录下，比如dir=/home/&#123;user&#125;/blog$ virtualenv venv #此时dir下生成一个venv文件夹$ source ./venv/bin/activate #激活虚拟环境（关闭虚拟环境 deactivate）#安装库$ pip install -r requirements.txt redis配置根据config.py设置的redis 密码，将/etc/redis/redis.conf 中设置成相应的密码 123$ sudo cp /etc/redis/redis.conf /usr/local/etc/redis.conf$ sudo vim /usr/local/etc/redis.conf #找到requirepass这一行，取消注释，并加上自己的password$ sudo redis-server /usr/local/etc/redis.conf #按照配置路径启动 postgresql配置根据config.py设置 ，SQLALCHEMY_DATABASE_URI = ‘postgresql://user:password@localhost/blog’，一个数据库名为’blog’, 用户是’user’，密码是’password’ 12345678$sudo -u postgres psqlpostgres= CREATE DATABASE blog;postgres= CREATE USER user WITH PASSWORD 'password';postgres= ALTER ROLE user SET client_encoding TO 'utf8';postgres= ALTER ROLE user SET default_transaction_isolation TO 'read committed';postgres= ALTER ROLE user SET timezone TO 'UTC';postgres= GRANT ALL PRIVILEGES ON DATABASE blog TO user;postgres= \q nginx安装和配置123456789101112131415161718192021222324252627#安装最新稳定版$echo deb http://nginx.org/packages/debian/ wheezy nginx &gt;&gt; /etc/apt/sources.list #更新库$echo deb-src http://nginx.org/packages/debian/ wheezy nginx &gt;&gt; /etc/apt/sources.list$wget http://nginx.org/keys/nginx_signing.key &amp;&amp; apt-key add nginx_signing.key #升级key$apt-get install nginx#配置文件$ sudo vim /etc/nginx/site-avaliable/blog添加以下内容server &#123; listen 80; server_name whistlestop.ml; # 域名， 用ip也行 location / &#123; proxy_pass http://127.0.0.1:8000; # gunicorn.py里的端口号 proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; $ cp /etc/nginx/sites-avaliable/blog /etc/nginx/sites-enabled/blog$ rm /etc/nginx/sites-enable/default #把原来的default文件删除#重启nginx$ sudo service nginx restart 启动博客1gunicorn --config gunicorn.py manager:app 后续要做的事 数据库备份 markdown预览功能 整个vps如何维护]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>flask</tag>
      </tags>
  </entry>
</search>
